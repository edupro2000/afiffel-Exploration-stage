{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sensitive-benchmark",
   "metadata": {},
   "source": [
    "### 네이버 영화리뷰 감성분석 도전하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-dutch",
   "metadata": {},
   "source": [
    "### 감성분석 사례\n",
    " - 마케팅 감성분석 사례 : https://dbr.donga.com/article/view/1202/article_no/8891/ac/magazine\n",
    " - 마케팅 감성분석 순서 : 데이터수집>데이터 전처리 > 형태소 사전의 구축 > 속성어(품사) 사전 구축 > 감성어 사전 구축 > 감성 분석 모형의 구축(감성어 사전별 점수 추출) 및 결과 도출(결과 계산)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facial-median",
   "metadata": {},
   "source": [
    "<mark><b>[진행 순서]</b>\n",
    "\n",
    "01. sentences 리스트 지정\n",
    "02. 파이썬 split() 메소드를 이용해 단어 단위로 문장을 쪼개기\n",
    "03. 텍스트: 인덱스 구조 만들기\n",
    "04. 텍스트 데이터 숫자로 변경하기\n",
    "05. 여러 개의 문장 리스트를 한꺼번에 숫자 텐서로 encode\n",
    "- 숫자 벡터로 encode된 문장을 원래대로 decode하기\n",
    "- 여러 개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하기\n",
    "06. 임베딩 처리 *<주의> keras.preprocessing.sequence.pad_sequences 함수로 길이 맞추기\n",
    "07. RNN 활용하기\n",
    "08. CNN 계열의 Conv1D 활용하기  (장점 : 병렬처리로 학습속도가 빠름)\n",
    "9. CNN 계열의 GlobalMaxPooling1D() 활용하기 (정해진 필터 크기에서 최댓값 추출)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "useful-lebanon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'feel', 'hungry']\n"
     ]
    }
   ],
   "source": [
    "# 1. 처리해야 할 문장을 파이썬 리스트에 옮겨 담았습니다.\n",
    "\n",
    "sentences=['i feel hungry', 'i eat lunch', 'now i feel happy']\n",
    "\n",
    "# 파이썬 split() 메소드를 이용해 단어 단위로 문장을 쪼개 봅니다.\n",
    "word_list = 'i feel hungry'.split()\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "patient-lottery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<PAD>', 1: '<BOS>', 2: '<UNK>', 3: 'i', 4: 'feel', 5: 'hungry', 6: 'eat', 7: 'lunch', 8: 'now', 9: 'happy'}\n"
     ]
    }
   ],
   "source": [
    "# 2. 파이썬 split() 메소드를 이용해 단어 단위로 문장을 쪼개기\n",
    "index_to_word={}  # 빈 딕셔너리를 만들기\n",
    "\n",
    "# 단어들을 하나씩 채우기\n",
    "# <BOS>, <PAD>, <UNK>는 관례적으로 딕셔너리 맨 앞에 넣어줍니다. \n",
    "index_to_word[0]='<PAD>'  # 패딩용 단어\n",
    "index_to_word[1]='<BOS>'  # 문장의 시작지점\n",
    "index_to_word[2]='<UNK>'  # 사전에 없는(Unknown) 단어\n",
    "index_to_word[3]='i'\n",
    "index_to_word[4]='feel'\n",
    "index_to_word[5]='hungry'\n",
    "index_to_word[6]='eat'\n",
    "index_to_word[7]='lunch'\n",
    "index_to_word[8]='now'\n",
    "index_to_word[9]='happy'\n",
    "\n",
    "print(index_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "false-convert",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<PAD>': 0, '<BOS>': 1, '<UNK>': 2, 'i': 3, 'feel': 4, 'hungry': 5, 'eat': 6, 'lunch': 7, 'now': 8, 'happy': 9}\n"
     ]
    }
   ],
   "source": [
    "# 3. 텍스트를 숫자로 변경시 {텍스트:인덱스} 구조여야 한다.\n",
    "\n",
    "word_to_index={word:index for index, word in index_to_word.items()}\n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "banned-democracy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(word_to_index['feel'])  # 단어 'feel'은 숫자 인덱스 4로 바뀝니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "respiratory-detail",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "# 4. 텍스트 데이터 숫자로 변경하기\n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "\n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] \n",
    "                                     if word in word_to_index \n",
    "                                     else word_to_index['<UNK>'] \n",
    "                                     for word in sentence.split()]\n",
    "\n",
    "print(get_encoded_sentence('i eat lunch', word_to_index)) #문장의 시작지점인 BOS 1, i 3,  eat 6,  lunch 7 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "offshore-diana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]]\n"
     ]
    }
   ],
   "source": [
    "# 5. 여러 개의 문장 리스트를 한꺼번에 숫자 텐서로 encode\n",
    "# get_encoded_sentence 함수 사용 하기(여러 개의 문장 리스트를 한꺼번에 숫자 텐서로 encode\n",
    "\n",
    "def get_encoded_sentences(sentences, word_to_index): \n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# encode 백터 변환 1. sentences 리스트 참고\n",
    "encoded_sentences = get_encoded_sentences(sentences, word_to_index) \n",
    "print(encoded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "interstate-digit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i feel hungry\n"
     ]
    }
   ],
   "source": [
    "# 기타1. 숫자 벡터로 encode된 문장을 원래대로 decode하기\n",
    " \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "print(get_decoded_sentence([1, 3, 4, 5], index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "australian-aluminum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i feel hungry', 'i eat lunch', 'now i feel happy']\n"
     ]
    }
   ],
   "source": [
    "# 기타2.여러 개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하기\n",
    "\n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]\n",
    "\n",
    "# 7. encoded_sentence 리스트 변환  \n",
    "print(get_decoded_sentences(encoded_sentences, index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "killing-street",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:12: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-3.62790003e-02  2.35451572e-02 -2.72021536e-02  1.12747326e-02]\n",
      "  [ 3.44746001e-02  6.08034059e-03 -2.88340803e-02  4.91940863e-02]\n",
      "  [ 1.95310600e-02  3.64458226e-02  4.89302538e-02 -1.47814676e-03]\n",
      "  [-1.62940845e-02  3.97322327e-03 -3.15822139e-02 -1.98922306e-03]\n",
      "  [-4.14770842e-02 -2.51033437e-02  1.61983855e-02  1.47389211e-02]]\n",
      "\n",
      " [[-3.62790003e-02  2.35451572e-02 -2.72021536e-02  1.12747326e-02]\n",
      "  [ 3.44746001e-02  6.08034059e-03 -2.88340803e-02  4.91940863e-02]\n",
      "  [-3.57899182e-02  1.95243023e-02 -4.72370535e-03  1.45143755e-02]\n",
      "  [ 1.59558542e-02  6.04356453e-03 -7.43754208e-05  1.31484382e-02]\n",
      "  [-4.14770842e-02 -2.51033437e-02  1.61983855e-02  1.47389211e-02]]\n",
      "\n",
      " [[-3.62790003e-02  2.35451572e-02 -2.72021536e-02  1.12747326e-02]\n",
      "  [ 2.11765282e-02  1.20259635e-02  2.34015249e-02  2.42548920e-02]\n",
      "  [ 3.44746001e-02  6.08034059e-03 -2.88340803e-02  4.91940863e-02]\n",
      "  [ 1.95310600e-02  3.64458226e-02  4.89302538e-02 -1.47814676e-03]\n",
      "  [-3.69032398e-02 -3.76222357e-02  2.58270837e-02 -4.49033491e-02]]], shape=(3, 5, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 6. 임베딩 처리 *raw_inputs 에 keras.preprocessing.sequence.pad_sequences 함수를 사용하여 패딩처리도 같이 진행\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4    # 그림과 같이 4차원의 워드 벡터를 가정합니다.\n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index)) # embedding 레이어의 input이 될 수 있음에 주의 \n",
    "\n",
    "\n",
    "raw_inputs = keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post', #RNN은 입력데이터가 순차적으로 처리 마지막 입력이 무의미, 'pre'가 훨씬 유리\n",
    "                                                       maxlen=5)\n",
    "output = embedding(raw_inputs)\n",
    "print(output) # output의 shape의 3은 입력문장 개수, 5는 maxlen(입력문장의 최대 길이), 4는 word_vector_dim(워드 벡터의 차원 수)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classical-rebate",
   "metadata": {},
   "source": [
    "### RNN 모델의 종류\n",
    "- 참고 : https://www.youtube.com/watch?v=-SHPG_KMUkQ&t=38s , [도서] 처음배우는 딥러닝 챗봇\n",
    "\n",
    "- many to one : 데이터를 입력 받아 정산인지 비정상인지 판단 예) 스팸인지 판단하는 모델\n",
    "\n",
    "- many to many 1 : 하나를 입력 받아 여러개를 출력 예) 이미지를 입력시 이미지를 설명하는 텍스트 출력\n",
    "\n",
    "- many to many 2 : 여러개 입력 받아 여러개 출력  예) 동영상 실시간 프레임에 대한 분석 결과를 출력, 번역기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "brave-reliance",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 8)                 416       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 537\n",
      "Trainable params: 537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 7. RNN 모델 활용하기 \n",
    "\n",
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4  # 단어 하나를 표현하는 임베딩 벡터의 차원수입니다. \n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경 가능)\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "coated-paint",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 16)          464       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,457\n",
      "Trainable params: 2,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 8. CNN 계열의 Conv1D 활용하기 (장점 : 병렬처리로 학습속도가 빠름)\n",
    "\n",
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원 수입니다. \n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(5))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "tutorial-charleston",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 9. CNN 계열의 GlobalMaxPooling1D() 활용하기 (정해진 필터 크기에서 최댓값 추출)\n",
    "\n",
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원 수입니다. \n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-elizabeth",
   "metadata": {},
   "source": [
    "### IMDb 영화리뷰 감성분석 태스크 도전\n",
    "- 긍정1, 부정0 라벨, 5만개 영어 리뷰 텍스트로 구성(훈련용 데이터 50%, 테스트용 데이터 50% 사용하도록 지정)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-execution",
   "metadata": {},
   "source": [
    "<mark><b>[진행 순서]</b>\n",
    "\n",
    "1. 데이터셋 다운로드 (encode된 텍스트 데이터를 다운로드) https://wikidocs.net/24586\n",
    "2. 데이터셋 확인하기\n",
    "- word_to_index 확인하기\n",
    "3. word_to_index, index_to_word 보정\n",
    "4. decode 된 데이터셋 확인\n",
    "5. 케라스 패딩을 위한 도구  pad_sequences() 로 활용하기 https://wikidocs.net/83544\n",
    "- 넘파이 padding='post': 뒤에 0을 채운다.\n",
    "- 케라스 pad_sequences : 앞에 0을 채운다.\n",
    "- max_len의 인자로 정수를 주면, 해당 정수로 모든 문서의 길이를 동일하게 한다.\n",
    "- padding 방식 변경해 보기 -뒤쪽('post') \n",
    "- padding 방식 변경해 보기 -앞쪽('pre') *RNN은 입력데이터가 순차적으로 처리 마지막 입력이 무의미, 'pre'가 훨씬 유리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "sweet-quantum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플 개수: 25000, 테스트 개수: 25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "# 1. 데이터셋 다운로드 ( encode된 텍스트 데이터를 다운로드)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)\n",
    "imdb = keras.datasets.imdb\n",
    "\n",
    "# IMDb 데이터셋 다운로드 \n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "print(\"훈련 샘플 개수: {}, 테스트 개수: {}\".format(len(x_train), len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "elementary-speech",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "라벨:  1\n",
      "1번째 리뷰 문장 길이:  218\n",
      "2번째 리뷰 문장 길이:  189\n"
     ]
    }
   ],
   "source": [
    "# 2. 데이터셋 확인하기\n",
    "\n",
    "print(x_train[0])  # 1번째 리뷰데이터\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨\n",
    "print('1번째 리뷰 문장 길이: ', len(x_train[0]))\n",
    "print('2번째 리뷰 문장 길이: ', len(x_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "modern-equilibrium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# word_to_index 확인하기\n",
    "\n",
    "word_to_index = imdb.get_word_index() # imdb.get_word_index()에 각 단어와 맵핑되는 정수가 저장되어 있음\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "print(index_to_word[1])     # 'the' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 1 이 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "overall-large",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOS>\n",
      "4\n",
      "the\n"
     ]
    }
   ],
   "source": [
    "# 3. word_to_index, index_to_word 보정\n",
    "#  <주의> IMDB 리뷰 데이터셋에서 정한 규칙 : imdb.get_word_index()에 저장된 값에 +3을 해야 실제 맵핑\n",
    "\n",
    "#실제 인코딩 인덱스는 제공된 word_to_index에서 index 기준으로 3씩 뒤로 밀려 있습니다.  \n",
    "word_to_index = {k:(v+3) for k,v in word_to_index.items()}\n",
    "\n",
    "# 처음 몇 개 인덱스는 사전에 정의되어 있습니다\n",
    "word_to_index[\"<PAD>\"] = 0\n",
    "word_to_index[\"<BOS>\"] = 1\n",
    "word_to_index[\"<UNK>\"] = 2  # unknown\n",
    "word_to_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "index_to_word[0] = \"<PAD>\"\n",
    "index_to_word[1] = \"<BOS>\"\n",
    "index_to_word[2] = \"<UNK>\"\n",
    "index_to_word[3] = \"<UNUSED>\"\n",
    "\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "\n",
    "print(index_to_word[1])     # '<BOS>' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 4 이 출력됩니다. \n",
    "print(index_to_word[4])     # 'the' 가 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "medium-eagle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
      "라벨:  1\n"
     ]
    }
   ],
   "source": [
    "# 4. decode 된 데이터셋 확인\n",
    "\n",
    "print(get_decoded_sentence(x_train[0], index_to_word))\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "signed-quebec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  234.75892\n",
      "문장길이 최대 :  2494\n",
      "문장길이 표준편차 :  172.91149458735703\n",
      "pad_sequences maxlen :  580\n",
      "전체 문장의 0.94536%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "# 5. 케라스 패딩을 위한 도구  pad_sequences() 로 활용하기 \n",
    "\n",
    "total_data_text = list(x_train) + list(x_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "#max_len의 인자로 정수를 주면, 해당 정수로 모든 문서의 길이를 동일하게 하며 값설젇이 전체 모델 성능에 영향\n",
    "print('pad_sequences maxlen : ', maxlen) \n",
    "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "reported-emission",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 580)\n"
     ]
    }
   ],
   "source": [
    "# padding 방식 변경해 보기  -뒤쪽('post') \n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='post', # 혹은 'pre'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='post', # 혹은 'pre'\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "committed-african",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 580)\n"
     ]
    }
   ],
   "source": [
    "# padding 방식 변경해 보기 -앞쪽('pre')  *RNN은 입력데이터가 순차적으로 처리 마지막 입력이 무의미, 'pre'가 훨씬 유리\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='pre', # 혹은 'pre'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='pre', # 혹은 'pre'\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(x_train.shape)  #이번 데이터셋은 차이를 모르겠음.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certain-sheep",
   "metadata": {},
   "source": [
    "### IMDb 영화리뷰 감성분석 딥러닝 모델 설계와 훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minor-fleet",
   "metadata": {},
   "source": [
    "<mark><b>[진행 순서]</b>\n",
    "\n",
    "1. RNN 모델 설계\n",
    "2. 훈련용 데이터셋 10000건을 분리하여 검증셋(validation set)으로 사용\n",
    "3. 모델 학습\n",
    "4. 모델 테스트셋으로 평가\n",
    "5. epoch에 따른 그래프를 그려볼 수 있는 항목들\n",
    "6. 그래프 Training and validation loss로 트레이닝 최적점 추정\n",
    "7. 그래프 Training and validation accuracy 로 트레이닝 최적점 추정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "solid-aggregate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 8)                 800       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 160,881\n",
      "Trainable params: 160,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 1. RNN 모델 설계\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 16  # 워드 벡터의 차원 수 (변경 가능한 하이퍼파라미터)\n",
    "\n",
    "# model 설계(직접작성)\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경 가능)\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "diagnostic-medication",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 580)\n",
      "(15000,)\n"
     ]
    }
   ],
   "source": [
    "# 2. 훈련용 데이터셋 10000건을 분리하여 검증셋(validation set)으로 사용\n",
    "\n",
    "# validation set 10000건 분리\n",
    "x_val = x_train[:10000]   \n",
    "y_val = y_train[:10000]\n",
    "\n",
    "# validation set을 제외한 나머지 15000건\n",
    "partial_x_train = x_train[10000:]  \n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "print(partial_x_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "conditional-orlando",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 7s 139ms/step - loss: 0.6932 - accuracy: 0.5004 - val_loss: 0.6931 - val_accuracy: 0.5020\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 3s 107ms/step - loss: 0.6931 - accuracy: 0.5041 - val_loss: 0.6932 - val_accuracy: 0.5025\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 3s 107ms/step - loss: 0.6929 - accuracy: 0.5170 - val_loss: 0.6933 - val_accuracy: 0.5033\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 3s 107ms/step - loss: 0.6925 - accuracy: 0.5275 - val_loss: 0.6930 - val_accuracy: 0.5025\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 3s 105ms/step - loss: 0.6923 - accuracy: 0.5159 - val_loss: 0.6927 - val_accuracy: 0.5030\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 3s 106ms/step - loss: 0.6910 - accuracy: 0.5209 - val_loss: 0.6921 - val_accuracy: 0.5042\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 3s 106ms/step - loss: 0.6884 - accuracy: 0.5189 - val_loss: 0.6912 - val_accuracy: 0.5034\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 3s 104ms/step - loss: 0.6839 - accuracy: 0.5217 - val_loss: 0.6890 - val_accuracy: 0.5102\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 3s 104ms/step - loss: 0.6745 - accuracy: 0.5331 - val_loss: 0.6871 - val_accuracy: 0.5131\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 3s 104ms/step - loss: 0.6946 - accuracy: 0.5730 - val_loss: 0.6927 - val_accuracy: 0.5105\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 3s 103ms/step - loss: 0.6793 - accuracy: 0.5372 - val_loss: 0.6899 - val_accuracy: 0.5094\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 3s 103ms/step - loss: 0.6748 - accuracy: 0.5434 - val_loss: 0.6888 - val_accuracy: 0.5096\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 3s 103ms/step - loss: 0.6736 - accuracy: 0.5411 - val_loss: 0.6888 - val_accuracy: 0.5100\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 3s 103ms/step - loss: 0.6708 - accuracy: 0.5426 - val_loss: 0.6881 - val_accuracy: 0.5110\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 3s 103ms/step - loss: 0.6667 - accuracy: 0.5401 - val_loss: 0.6871 - val_accuracy: 0.5126\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 3s 103ms/step - loss: 0.6643 - accuracy: 0.5386 - val_loss: 0.6860 - val_accuracy: 0.5141\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 3s 102ms/step - loss: 0.6626 - accuracy: 0.5353 - val_loss: 0.6851 - val_accuracy: 0.5159\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 3s 102ms/step - loss: 0.6570 - accuracy: 0.5407 - val_loss: 0.6846 - val_accuracy: 0.5176\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 3s 101ms/step - loss: 0.6558 - accuracy: 0.5395 - val_loss: 0.6854 - val_accuracy: 0.5184\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 3s 100ms/step - loss: 0.6544 - accuracy: 0.5375 - val_loss: 0.6977 - val_accuracy: 0.5126\n"
     ]
    }
   ],
   "source": [
    "# 3. 모델 학습\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "social-belarus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 21s - loss: 0.6952 - accuracy: 0.5096\n",
      "[0.6952013969421387, 0.5095999836921692]\n"
     ]
    }
   ],
   "source": [
    "# 4. 모델 테스트셋으로 평가\n",
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "usual-volunteer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "# 5.epoch에 따른 그래프를 그려볼 수 있는 항목들\n",
    "history_dict = history.history\n",
    "print(history_dict.keys()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "guilty-thanks",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 6. 그래프 Training and validation loss로 트레이닝 최적점 추정\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"입니다\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b는 \"파란 실선\"입니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs') # Epochs 19정도에 lOSS가 제일 낮다.\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "involved-athletics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 7. 그래프 Training and validation accuracy 로 트레이닝 최적점 추정\n",
    "\n",
    "plt.clf()   # 그림을 초기화합니다\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs') # Epochs 10, 19정도에 Accuracy가 제일 높다.\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diverse-drink",
   "metadata": {},
   "source": [
    "### IMDb 영화리뷰 감성분석 Word2Vec (연관단어 유추)\n",
    "- CBOW 모델 : 맥락이라 표현되는 주변 단어들을 이용해 타깃 단어를 예측 ( 예: 오늘(주변단어) ___ (타깃단어)는 폭염이(주변단어) 심해요.)\n",
    "- Skip-gram 모델 : 하나의 타깃 단어를 이용해 주변 단어들을 예측 ( 예: ----(주변단어) 치킨과(타깃단어)  --(주변단어)를 먹고 싶네요.)\n",
    "- 워드 벡터를 다루기 위해 pip list | grep gensim 으로 패키지 버전 확인 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latter-sussex",
   "metadata": {},
   "source": [
    "<mark><b>[진행 순서]</b>\n",
    "\n",
    "1. RNN 모델 설계\n",
    "2. 훈련용 데이터셋 10000건을 분리하여 검증셋(validation set)으로 사용\n",
    "3. 모델 학습\n",
    "4. 모델 테스트셋으로 평가\n",
    "5. epoch에 따른 그래프를 그려볼 수 있는 항목들\n",
    "6. 그래프 Training and validation loss로 트레이닝 최적점 추정\n",
    "7. 그래프 Training and validation accuracy 로 트레이닝 최적점 추정\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "unlikely-access",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)    # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "hungry-basics",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 학습한 Embedding 파라미터를 파일에 써서 저장합니다. \n",
    "word2vec_file_path = os.getenv('HOME')+'/aiffel/sentiment_classification/data/word2vec.txt'\n",
    "f = open(word2vec_file_path, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim))  # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀을 씁니다.\n",
    "\n",
    "# 단어 개수(에서 특수문자 4개는 제외하고)만큼의 워드 벡터를 파일에 기록합니다. \n",
    "vectors = model.get_weights()[0]\n",
    "for i in range(4,vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ideal-fabric",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.02726495, -0.0307985 , -0.04846679,  0.00099088,  0.09673243,\n",
       "        0.10022417,  0.06375012,  0.03707759, -0.08080702, -0.09777314,\n",
       "       -0.03772826,  0.06291641, -0.03981373,  0.08056346,  0.06454742,\n",
       "       -0.10869022], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "vector = word_vectors['computer']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "celtic-quarterly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('forgiven', 0.8262287378311157),\n",
       " ('situations', 0.7804450392723083),\n",
       " ('nostalgic', 0.7531030774116516),\n",
       " ('shoe', 0.7499609589576721),\n",
       " ('of', 0.7454351186752319),\n",
       " ('wild', 0.7394944429397583),\n",
       " ('fi', 0.7391157150268555),\n",
       " ('everyone', 0.7352408766746521),\n",
       " ('does', 0.7328805327415466),\n",
       " ('outrageous', 0.7312945127487183)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "wooden-committee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.07421875e-01, -2.01171875e-01,  1.23046875e-01,  2.11914062e-01,\n",
       "       -9.13085938e-02,  2.16796875e-01, -1.31835938e-01,  8.30078125e-02,\n",
       "        2.02148438e-01,  4.78515625e-02,  3.66210938e-02, -2.45361328e-02,\n",
       "        2.39257812e-02, -1.60156250e-01, -2.61230469e-02,  9.71679688e-02,\n",
       "       -6.34765625e-02,  1.84570312e-01,  1.70898438e-01, -1.63085938e-01,\n",
       "       -1.09375000e-01,  1.49414062e-01, -4.65393066e-04,  9.61914062e-02,\n",
       "        1.68945312e-01,  2.60925293e-03,  8.93554688e-02,  6.49414062e-02,\n",
       "        3.56445312e-02, -6.93359375e-02, -1.46484375e-01, -1.21093750e-01,\n",
       "       -2.27539062e-01,  2.45361328e-02, -1.24511719e-01, -3.18359375e-01,\n",
       "       -2.20703125e-01,  1.30859375e-01,  3.66210938e-02, -3.63769531e-02,\n",
       "       -1.13281250e-01,  1.95312500e-01,  9.76562500e-02,  1.26953125e-01,\n",
       "        6.59179688e-02,  6.93359375e-02,  1.02539062e-02,  1.75781250e-01,\n",
       "       -1.68945312e-01,  1.21307373e-03, -2.98828125e-01, -1.15234375e-01,\n",
       "        5.66406250e-02, -1.77734375e-01, -2.08984375e-01,  1.76757812e-01,\n",
       "        2.38037109e-02, -2.57812500e-01, -4.46777344e-02,  1.88476562e-01,\n",
       "        5.51757812e-02,  5.02929688e-02, -1.06933594e-01,  1.89453125e-01,\n",
       "       -1.16210938e-01,  8.49609375e-02, -1.71875000e-01,  2.45117188e-01,\n",
       "       -1.73828125e-01, -8.30078125e-03,  4.56542969e-02, -1.61132812e-02,\n",
       "        1.86523438e-01, -6.05468750e-02, -4.17480469e-02,  1.82617188e-01,\n",
       "        2.20703125e-01, -1.22558594e-01, -2.55126953e-02, -3.08593750e-01,\n",
       "        9.13085938e-02,  1.60156250e-01,  1.70898438e-01,  1.19628906e-01,\n",
       "        7.08007812e-02, -2.64892578e-02, -3.08837891e-02,  4.06250000e-01,\n",
       "       -1.01562500e-01,  5.71289062e-02, -7.26318359e-03, -9.17968750e-02,\n",
       "       -1.50390625e-01, -2.55859375e-01,  2.16796875e-01, -3.63769531e-02,\n",
       "        2.24609375e-01,  8.00781250e-02,  1.56250000e-01,  5.27343750e-02,\n",
       "        1.50390625e-01, -1.14746094e-01, -8.64257812e-02,  1.19140625e-01,\n",
       "       -7.17773438e-02,  2.73437500e-01, -1.64062500e-01,  7.29370117e-03,\n",
       "        4.21875000e-01, -1.12792969e-01, -1.35742188e-01, -1.31835938e-01,\n",
       "       -1.37695312e-01, -7.66601562e-02,  6.25000000e-02,  4.98046875e-02,\n",
       "       -1.91406250e-01, -6.03027344e-02,  2.27539062e-01,  5.88378906e-02,\n",
       "       -3.24218750e-01,  5.41992188e-02, -1.35742188e-01,  8.17871094e-03,\n",
       "       -5.24902344e-02, -1.74713135e-03, -9.81445312e-02, -2.86865234e-02,\n",
       "        3.61328125e-02,  2.15820312e-01,  5.98144531e-02, -3.08593750e-01,\n",
       "       -2.27539062e-01,  2.61718750e-01,  9.86328125e-02, -5.07812500e-02,\n",
       "        1.78222656e-02,  1.31835938e-01, -5.35156250e-01, -1.81640625e-01,\n",
       "        1.38671875e-01, -3.10546875e-01, -9.71679688e-02,  1.31835938e-01,\n",
       "       -1.16210938e-01,  7.03125000e-02,  2.85156250e-01,  3.51562500e-02,\n",
       "       -1.01562500e-01, -3.75976562e-02,  1.41601562e-01,  1.42578125e-01,\n",
       "       -5.68847656e-02,  2.65625000e-01, -2.09960938e-01,  9.64355469e-03,\n",
       "       -6.68945312e-02, -4.83398438e-02, -6.10351562e-02,  2.45117188e-01,\n",
       "       -9.66796875e-02,  1.78222656e-02, -1.27929688e-01, -4.78515625e-02,\n",
       "       -7.26318359e-03,  1.79687500e-01,  2.78320312e-02, -2.10937500e-01,\n",
       "       -1.43554688e-01, -1.27929688e-01,  1.73339844e-02, -3.60107422e-03,\n",
       "       -2.04101562e-01,  3.63159180e-03, -1.19628906e-01, -6.15234375e-02,\n",
       "        5.93261719e-02, -3.23486328e-03, -1.70898438e-01, -3.14941406e-02,\n",
       "       -8.88671875e-02, -2.89062500e-01,  3.44238281e-02, -1.87500000e-01,\n",
       "        2.94921875e-01,  1.58203125e-01, -1.19628906e-01,  7.61718750e-02,\n",
       "        6.39648438e-02, -4.68750000e-02, -6.83593750e-02,  1.21459961e-02,\n",
       "       -1.44531250e-01,  4.54101562e-02,  3.68652344e-02,  3.88671875e-01,\n",
       "        1.45507812e-01, -2.55859375e-01, -4.46777344e-02, -1.33789062e-01,\n",
       "       -1.38671875e-01,  6.59179688e-02,  1.37695312e-01,  1.14746094e-01,\n",
       "        2.03125000e-01, -4.78515625e-02,  1.80664062e-02, -8.54492188e-02,\n",
       "       -2.48046875e-01, -3.39843750e-01, -2.83203125e-02,  1.05468750e-01,\n",
       "       -2.14843750e-01, -8.74023438e-02,  7.12890625e-02,  1.87500000e-01,\n",
       "       -1.12304688e-01,  2.73437500e-01, -3.26171875e-01, -1.77734375e-01,\n",
       "       -4.24804688e-02, -2.69531250e-01,  6.64062500e-02, -6.88476562e-02,\n",
       "       -1.99218750e-01, -7.03125000e-02, -2.43164062e-01, -3.66210938e-02,\n",
       "       -7.37304688e-02, -1.77734375e-01,  9.17968750e-02, -1.25000000e-01,\n",
       "       -1.65039062e-01, -3.57421875e-01, -2.85156250e-01, -1.66992188e-01,\n",
       "        1.97265625e-01, -1.53320312e-01,  2.31933594e-02,  2.06054688e-01,\n",
       "        1.80664062e-01, -2.74658203e-02, -1.92382812e-01, -9.61914062e-02,\n",
       "       -1.06811523e-02, -4.73632812e-02,  6.54296875e-02, -1.25732422e-02,\n",
       "        1.78222656e-02, -8.00781250e-02, -2.59765625e-01,  9.37500000e-02,\n",
       "       -7.81250000e-02,  4.68750000e-02, -2.22167969e-02,  1.86767578e-02,\n",
       "        3.11279297e-02,  1.04980469e-02, -1.69921875e-01,  2.58789062e-02,\n",
       "       -3.41796875e-02, -1.44042969e-02, -5.46875000e-02, -8.78906250e-02,\n",
       "        1.96838379e-03,  2.23632812e-01, -1.36718750e-01,  1.75781250e-01,\n",
       "       -1.63085938e-01,  1.87500000e-01,  3.44238281e-02, -5.63964844e-02,\n",
       "       -2.27689743e-05,  4.27246094e-02,  5.81054688e-02, -1.07910156e-01,\n",
       "       -3.88183594e-02, -2.69531250e-01,  3.34472656e-02,  9.81445312e-02,\n",
       "        5.63964844e-02,  2.23632812e-01, -5.49316406e-02,  1.46484375e-01,\n",
       "        5.93261719e-02, -2.19726562e-01,  6.39648438e-02,  1.66015625e-02,\n",
       "        4.56542969e-02,  3.26171875e-01, -3.80859375e-01,  1.70898438e-01,\n",
       "        5.66406250e-02, -1.04492188e-01,  1.38671875e-01, -1.57226562e-01,\n",
       "        3.23486328e-03, -4.80957031e-02, -2.48046875e-01, -6.20117188e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Google의 Word2Vec 모델을 가져와 적용\n",
    "# <준비> 클라우드 쉘에서 심볼링 링크를 연결하여 원본 파일을 직접 사용하는 것과 같은 효과를 내도록함\n",
    "# 심볼링 링크  : ln -s ~/data/GoogleNews-vectors-negative300.bin.gz ~/aiffel 주소~\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "word2vec_path = os.getenv('HOME')+'/aiffel/sentiment_classification/data/GoogleNews-vectors-negative300.bin.gz'\n",
    "word2vec = KeyedVectors.load_word2vec_format(word2vec_path, binary=True, limit=1000000)\n",
    "vector = word2vec['computer']\n",
    "vector     # 무려 300dim의 워드 벡터입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "mature-sucking",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('loved', 0.6907791495323181),\n",
       " ('adore', 0.6816873550415039),\n",
       " ('loves', 0.661863386631012),\n",
       " ('passion', 0.6100708842277527),\n",
       " ('hate', 0.600395679473877),\n",
       " ('loving', 0.5886635780334473),\n",
       " ('affection', 0.5664337873458862),\n",
       " ('undying_love', 0.5547304749488831),\n",
       " ('absolutely_adore', 0.5536840558052063),\n",
       " ('adores', 0.5440906882286072)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 메모리를 다소 많이 소비하는 작업이니 유의해 주세요.\n",
    "word2vec.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "political-incentive",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드 벡터를 단어 하나씩마다 차례차례 카피한다.\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word2vec:\n",
    "        embedding_matrix[i] = word2vec[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "sound-handling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 580, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 574, 16)           33616     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 114, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 108, 16)           1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,035,569\n",
      "Trainable params: 3,035,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원 수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "# 모델 구성\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(5))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "premium-process",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 17s 456ms/step - loss: 0.7317 - accuracy: 0.5066 - val_loss: 0.6830 - val_accuracy: 0.5630\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 11s 360ms/step - loss: 0.6587 - accuracy: 0.6260 - val_loss: 0.6461 - val_accuracy: 0.6353\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 11s 358ms/step - loss: 0.5801 - accuracy: 0.7351 - val_loss: 0.5387 - val_accuracy: 0.7226\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 11s 356ms/step - loss: 0.4250 - accuracy: 0.8299 - val_loss: 0.3847 - val_accuracy: 0.8366\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 11s 356ms/step - loss: 0.2768 - accuracy: 0.9041 - val_loss: 0.3460 - val_accuracy: 0.8500\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 11s 356ms/step - loss: 0.2006 - accuracy: 0.9326 - val_loss: 0.3151 - val_accuracy: 0.8685\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 11s 355ms/step - loss: 0.1393 - accuracy: 0.9623 - val_loss: 0.3117 - val_accuracy: 0.8730\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 11s 357ms/step - loss: 0.0936 - accuracy: 0.9805 - val_loss: 0.3217 - val_accuracy: 0.8727\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 11s 357ms/step - loss: 0.0623 - accuracy: 0.9917 - val_loss: 0.3305 - val_accuracy: 0.8717\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 11s 357ms/step - loss: 0.0425 - accuracy: 0.9965 - val_loss: 0.3419 - val_accuracy: 0.8714\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 11s 356ms/step - loss: 0.0270 - accuracy: 0.9990 - val_loss: 0.3538 - val_accuracy: 0.8736\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 11s 355ms/step - loss: 0.0181 - accuracy: 0.9993 - val_loss: 0.3740 - val_accuracy: 0.8738\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 11s 357ms/step - loss: 0.0131 - accuracy: 0.9996 - val_loss: 0.3872 - val_accuracy: 0.8733\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 11s 357ms/step - loss: 0.0092 - accuracy: 0.9999 - val_loss: 0.4072 - val_accuracy: 0.8738\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 11s 357ms/step - loss: 0.0070 - accuracy: 0.9998 - val_loss: 0.4199 - val_accuracy: 0.8745\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 11s 357ms/step - loss: 0.0053 - accuracy: 0.9999 - val_loss: 0.4339 - val_accuracy: 0.8739\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 11s 357ms/step - loss: 0.0042 - accuracy: 0.9999 - val_loss: 0.4477 - val_accuracy: 0.8753\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 11s 357ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.4601 - val_accuracy: 0.8736\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 11s 356ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.4723 - val_accuracy: 0.8736\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 11s 357ms/step - loss: 0.0026 - accuracy: 0.9997 - val_loss: 0.4840 - val_accuracy: 0.8732\n"
     ]
    }
   ],
   "source": [
    "# 학습의 진행\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "intellectual-progressive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 8s - loss: 0.5163 - accuracy: 0.8647\n",
      "[0.5162529349327087, 0.8647199869155884]\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋을 통한 모델 평가\n",
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tender-christmas",
   "metadata": {},
   "source": [
    "## 회고\n",
    "1.*RNN은 입력데이터가 순차적으로 처리 마지막 입력이 무의미, 'pre'가 훨씬 유리하다는데 현재 데이터에선 같은 값으로 확인됨..\n",
    "2. Training and validation loss 그래프의 Epochs 19정도에 lOSS가 제일 낮고, Training and validation accuracy 그래프의 Epochs 10, 19정도에 Accuracy가 제일 높다. 이에 19가 최적점으로 추정된다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
