{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "willing-pipeline",
   "metadata": {},
   "source": [
    "# 프로젝트: Vocabulary Size를 변경해서 시도해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "collaborative-charity",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import reuters\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pending-fiber",
   "metadata": {},
   "source": [
    "#### 1) 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "agricultural-cover",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
      "2113536/2110848 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/datasets/reuters.py:148: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/datasets/reuters.py:149: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=None, test_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "concrete-science",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플의 수: 8982\n",
      "테스트 샘플의 수: 2246\n"
     ]
    }
   ],
   "source": [
    "# 로드 데이터의 구성 확인\n",
    "print('훈련 샘플의 수: {}'.format(len(x_train)))\n",
    "print('테스트 샘플의 수: {}'.format(len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "blocked-classic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스의 수 : 46\n"
     ]
    }
   ],
   "source": [
    "# 레이블 숫자 0부터 시작되므로 최댓값구한후 1더하면 현재 클래스 개수 확인 가능\n",
    "\n",
    "num_classes = max(y_train) + 1\n",
    "print('클래스의 수 : {}'.format(num_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charitable-influence",
   "metadata": {},
   "source": [
    "#### 2) 데이터 복원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "enhanced-earthquake",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters_word_index.json\n",
      "557056/550378 [==============================] - 0s 0us/step\n",
      "=3\n"
     ]
    }
   ],
   "source": [
    "# 제공된 로이터 뉴스 데이터를 단어key key값으로, 고유한 정수를 value로 가지는 dictionary를 word_index로 저장\n",
    "\n",
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "swedish-potential",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "# <로이터 뉴스 데이터 정의> word_index에 입력으로 했을 때, 얻는 숫자보다는 +3을 한 숫자가 원래 고유한 숫자\n",
    "    \n",
    "index_to_word = { index+3 : word for word, index in word_index.items() }\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baking-religious",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "#<로이터 뉴스 데이터 정의>  <pad>, <sos>, <unk> 자연어 처리를 위한 맵핑 번호\n",
    "\n",
    "# index_to_word에 숫자 0은 <pad>, 숫자 1은 <sos>, 숫자 2는 <unk>를 넣어줍니다.\n",
    "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "  index_to_word[index]=token\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "backed-italic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> mcgrath rentcorp said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n"
     ]
    }
   ],
   "source": [
    "# index_to_word 를 통해 텍스트로 원래 복원하기\n",
    "\n",
    "print(' '.join([index_to_word[index] for index in x_train[0]])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "vulnerable-adrian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8982\n"
     ]
    }
   ],
   "source": [
    "# 이제 전체 훈련용 뉴스 데이터와 전체 테스트용 뉴스 데이터를 텍스트 데이터로 변환\n",
    "\n",
    "decoded = []\n",
    "for i in range(len(x_train)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_train = decoded\n",
    "print(len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "driven-blake",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246\n"
     ]
    }
   ],
   "source": [
    "decoded = []\n",
    "for i in range(len(x_test)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_test = decoded\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "funded-disability",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos> mcgrath rentcorp said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "smoking-hardwood",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos> the great atlantic and pacific tea co said its three year 345 mln dlr capital program will be be substantially increased to accommodate growth and expansion plans for waldbaum inc and shopwell inc over the next two years a and p said the acquisition of shopwell in august 1986 and waldbaum in december helped us achieve better than expected results in the fourth quarter ended february 28 its net income from continuing operations jumped 52 6 pct to 20 7 mln dlrs or 55 cts a share in the latest quarter as sales increased 48 3 pct to 1 58 billion dlrs a and p gave no details on the expanded capital program but it did say it completed the first year of the program during 1986 a and p is 52 4 pct owned by lt tengelmann warenhandelsgesellschaft of west germany reuter 3']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parental-startup",
   "metadata": {},
   "source": [
    "#### 3) 벡터화 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "embedded-oliver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "filled-keeping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 26506)\n"
     ]
    }
   ],
   "source": [
    "# DTM 생성 및 DTM 크기 확인\n",
    "\n",
    "dtmvector = CountVectorizer()\n",
    "x_train_dtm = dtmvector.fit_transform(x_train)\n",
    "print(x_train_dtm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ahead-isolation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 26506)\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF Matrix는 사이킷런의 TfidfTransformer()를 통해서 생성\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidfv = tfidf_transformer.fit_transform(x_train_dtm)\n",
    "print(tfidfv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "surprised-disabled",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도 측정을 위해 테스트 데이터 전처리 필요, 이에 테스트 데이터 TF-IDF  행렬로 변환 필요\n",
    "\n",
    "x_test_dtm = dtmvector.transform(x_test) #테스트 데이터를 DTM으로 변환\n",
    "tfidfv_test = tfidf_transformer.transform(x_test_dtm) #DTM을 TF-IDF 행렬로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "whole-numbers",
   "metadata": {},
   "source": [
    "## 다양한 머신러닝 모델 사용해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "spiritual-possession",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB #다항분포 나이브 베이즈 모델\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score #정확도 계산\n",
    "\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "white-initial",
   "metadata": {},
   "source": [
    "### 1) Naive Bayes Classifier(NB)\n",
    "- 스팸메일 예 (https://youtu.be/3JWLIV3NaoQ)\n",
    "- P(coupon | spam) * P(spam)/ P(coupon) \n",
    "    - 총 8개의 메일 중 4개의 메일이 스팸 메일이므로 P(spam) = 4/8 = 1/2\n",
    "    - 총 8개의 메일 중 3개의 메일이 coupon이라는 단어를 포함하므로 P(coupon) = 3/8\n",
    "    - 총 4개의 스팸 메일 중 2개의 메일이 coupon이라는 단어를 포함하므로 P(coupon | spam) = 2/4 = 1/2\n",
    "    - 정답 2/3 즉, 66.7%     P(coupon | spam) * P(spam)/ P(coupon) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "instrumental-economy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()  # 나이브 베이즈 분류기\n",
    "model.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "falling-tokyo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.5997328584149599\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(tfidfv_test) #테스트 데이터에 대한 예측값을 얻어 정확도 측정\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "modular-operations",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sos> graham mccormick oil and gas partnership said it completed the sale of interests in two major oil and gas fields to lt energy assets international corp for 21 mln dlrs the company said it sold about one half of its 50 pct interest in the oak hill and north rucias fields its two largest producing properties it said it used about 20 mln dlrs of the proceeds to prepay principal on its senior secured notes semi annual principal payments on the remaining 40 mln dlrs of notes have been satisfied until december 1988 as a result it said the company said the note agreements were amended to reflect an easing of some financial covenants and an increase of interest to 13 5 pct from 13 0 pct until december 1990 it said the noteholders exercise price for 1 125 000 warrants was also reduced to 50 cts from 1 50 dlrs the company said energy assets agreed to share the costs of increasing production at the oak hill field reuter 3'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측 테스트\n",
    "\n",
    "x_test[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "opposed-representation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이 샘플의 레이블 확인\n",
    "\n",
    "y_test[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metropolitan-delay",
   "metadata": {},
   "source": [
    "#### F1-Score, Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stone-honey",
   "metadata": {},
   "source": [
    "- 분류성능평가지표 \n",
    "    - Precision(정밀도) : 정밀도란 모델이 True라고 분류한 것 중에서!! 실제 True인 것의 비율\n",
    "    - Recall(재현율) :실제 True인 것 중에서!!(전체범위) 모델이 True라고 예측한 것의 비율\n",
    "    - Accuracy(정확도) : 옮게 예측한 경우를 고려하는 지표\n",
    "    - F1 score : Precision과 Recall의 조화평균, 데이터 label이 불균형 구조일 때, 모델의 성능을 정확하게 평가, 성능 하나의 숫자로 표현가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "legal-justice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "annoying-avenue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.79      0.21      0.33       105\n",
      "           2       0.00      0.00      0.00        20\n",
      "           3       0.72      0.92      0.81       813\n",
      "           4       0.45      0.96      0.61       474\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.00      0.00      0.00        14\n",
      "           7       0.00      0.00      0.00         3\n",
      "           8       0.00      0.00      0.00        38\n",
      "           9       0.00      0.00      0.00        25\n",
      "          10       0.00      0.00      0.00        30\n",
      "          11       0.80      0.29      0.42        83\n",
      "          12       0.00      0.00      0.00        13\n",
      "          13       0.00      0.00      0.00        37\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00         9\n",
      "          16       0.75      0.18      0.29        99\n",
      "          17       0.00      0.00      0.00        12\n",
      "          18       0.00      0.00      0.00        20\n",
      "          19       0.73      0.58      0.64       133\n",
      "          20       0.00      0.00      0.00        70\n",
      "          21       0.00      0.00      0.00        27\n",
      "          22       0.00      0.00      0.00         7\n",
      "          23       0.00      0.00      0.00        12\n",
      "          24       0.00      0.00      0.00        19\n",
      "          25       0.00      0.00      0.00        31\n",
      "          26       0.00      0.00      0.00         8\n",
      "          27       0.00      0.00      0.00         4\n",
      "          28       0.00      0.00      0.00        10\n",
      "          29       0.00      0.00      0.00         4\n",
      "          30       0.00      0.00      0.00        12\n",
      "          31       0.00      0.00      0.00        13\n",
      "          32       0.00      0.00      0.00        10\n",
      "          33       0.00      0.00      0.00         5\n",
      "          34       0.00      0.00      0.00         7\n",
      "          35       0.00      0.00      0.00         6\n",
      "          36       0.00      0.00      0.00        11\n",
      "          37       0.00      0.00      0.00         2\n",
      "          38       0.00      0.00      0.00         3\n",
      "          39       0.00      0.00      0.00         5\n",
      "          40       0.00      0.00      0.00        10\n",
      "          41       0.00      0.00      0.00         8\n",
      "          42       0.00      0.00      0.00         3\n",
      "          43       0.00      0.00      0.00         6\n",
      "          44       0.00      0.00      0.00         5\n",
      "          45       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.60      2246\n",
      "   macro avg       0.09      0.07      0.07      2246\n",
      "weighted avg       0.50      0.60      0.50      2246\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 재현율, F1점수를 구하는 classification_report() 함수를 제공\n",
    "\n",
    "print(classification_report(y_test, model.predict(tfidfv_test), zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interracial-mistake",
   "metadata": {},
   "source": [
    "- macro: 단순평균\n",
    "- weighted avg: 각 클래스에 속하는 표본의 개수로 가중평균\n",
    "- accuracy avg : 정확도. 전체 학습 데이터의 개수에서 클래스를 정확하게 맞춘 개수의 비율"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charged-modem",
   "metadata": {},
   "source": [
    "#### 2) 컴플리먼트 나이브 베이즈 분류기(Complement Naive Bayes Classifier(CNB) )\n",
    "- 나이브 베이즈 분류기를 보완, 데이터의 불균형을 고려하여 가중치를 부여하는 특징이 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "strange-omaha",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ComplementNB()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb = ComplementNB()\n",
    "cb.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ready-storm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7649154051647373\n"
     ]
    }
   ],
   "source": [
    "predicted = cb.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developmental-cleaners",
   "metadata": {},
   "source": [
    "#### 3) 로지스틱 회귀(Logistic Regression)\n",
    "- 소프트맥스(softmax) 함수를 사용한 다중 클래스 분류 알고리즘을 지원\n",
    "    - 소프트맥스 함수는 클래스가 N개일 때, N차원의 벡터가 '각 클래스가 정답일 확률'을 표현하도록 정규화해주는 함수\n",
    "    - 다중 클래스 분류를 위한 로지스틱 회귀를 소프트맥스 회귀(Softmax Regression), <mark><주의> 이름은 회귀지만, 실제로는 분류를 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "meaningful-kenya",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10000)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 소프트맥스 회귀는 LogisticRegression()을 통해서 구현\n",
    "lr = LogisticRegression(C=10000, penalty='l2')\n",
    "lr.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "catholic-brazil",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.813446126447017\n"
     ]
    }
   ],
   "source": [
    "predicted = lr.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-trinidad",
   "metadata": {},
   "source": [
    "#### 4) 선형 서포트 벡터 머신(Linear Support Vector Machine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verified-logic",
   "metadata": {},
   "source": [
    "- 일대다 방식은 각 클래스를 다른 모든 클래스와 구분하도록 이진 분류 모델을 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "analyzed-professor",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1000, dual=False, max_iter=500, penalty='l1')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc = LinearSVC(C=1000, penalty='l1', max_iter=500, dual=False)\n",
    "lsvc.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "loved-catholic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.780053428317008\n"
     ]
    }
   ],
   "source": [
    "# 서포트 벡터 머신 사용하여 분류하기\n",
    "\n",
    "predicted = lsvc.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenging-species",
   "metadata": {},
   "source": [
    "#### 5) 결정 트리(Decision Tree)\n",
    "- 고차원, 희소한 데이터에는 성능이 나오지 않는 특징이 있다.\n",
    "- 데이터를 전부 다 사용한다. 가장 좋은 질문이 나온다.\n",
    "- 결정 트리는 훈련 데이터에 과적합(Overfitting)되는 경향"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "metric-establishment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=10, random_state=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=10, random_state=0)\n",
    "tree.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "european-sight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.6211041852181657\n"
     ]
    }
   ],
   "source": [
    "predicted = tree.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swedish-folks",
   "metadata": {},
   "source": [
    "#### 6) 랜덤 포레스트(Random Forest)\n",
    "- 여러개의 작은 나무들로 구성된 숲과 같다.\n",
    "- 중복된 데이터를 허용하므로서 모델의 편향이 올라간다.(오버피팅시 솔루션으로 사용된다)\n",
    "- 랜덤이므로 가장 좋은 질문이 나오지 않을수 있다.\n",
    "- 랜덤 포레스트는 이 문제를 앙상블로 해결. 가령 서로 다른 방향으로 과적합된 트리들을 조합하면 오히려 모델 전체에서 과적합을 피할 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "pleased-budget",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=5, random_state=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=5, random_state=0)\n",
    "forest.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "municipal-terry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.6544968833481746\n"
     ]
    }
   ],
   "source": [
    "predicted = forest.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-darkness",
   "metadata": {},
   "source": [
    "#### 7) 그래디언트 부스팅 트리(GradientBoostingClassifier) \n",
    "- 그래디언트 부스팅 트리는 여러 개의 결정 트리를 묶어 만드는 앙상블 모델\n",
    "- 그레디언트 부스팅은 랜덤 포레스트와 다르게 이전 트리의 오차를 보완하는 방식\n",
    "- 특징: 일부 특성을 무시 보통 랜덤포레스트 사용후 예측시간면에서 만족스럽지 않을때 그래디언트 부스팅 트리를 시도해보는것이 좋다. \n",
    "- 장점: 예측 속도가 빠르다\n",
    "- 단점: 훈련 시간의 속도가 좀 오래 걸리고, 트리 기반 모델의 특성으로 인해서 희소한 고차원 데이터에 대해서는 잘 동작하지 않는다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "located-village",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(random_state=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grbt = GradientBoostingClassifier(random_state=0) # verbose=3\n",
    "grbt.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "prospective-farming",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7702582368655387\n"
     ]
    }
   ],
   "source": [
    "predicted = grbt.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normal-cartridge",
   "metadata": {},
   "source": [
    "#### 8) 앙상블기법중  보팅(Voting) 투표방법\n",
    "- 하드 보팅 : 투표용지 1장, 결과물에 대한 최종값을 투표해서 결정\n",
    "- 소프트 보팅 : 최종 결과물이 나올 확률값을 다 더해서 최종 결과물에 대한 각각의 확률을 구한 뒤 최종값을 도출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "organizational-hearts",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(C=10000)),\n",
       "                             ('cb', ComplementNB()),\n",
       "                             ('grbt',\n",
       "                              GradientBoostingClassifier(random_state=0))],\n",
       "                 n_jobs=-1, voting='soft')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 로지스틱 회귀, CNB, 그래디언트 부스팅 트리 모델을 사용하여 소프트 보팅을 하였을 때의 성능을 비교\n",
    "voting_classifier = VotingClassifier(estimators=[\n",
    "         ('lr', LogisticRegression(C=10000, penalty='l2')),\n",
    "        ('cb', ComplementNB()),\n",
    "        ('grbt', GradientBoostingClassifier(random_state=0))\n",
    "], voting='soft', n_jobs=-1)\n",
    "voting_classifier.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "quarterly-norway",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.8187889581478184\n"
     ]
    }
   ],
   "source": [
    "predicted = voting_classifier.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advance-kinase",
   "metadata": {},
   "source": [
    "[num_words = none 단어 머신러닝 정확도 결과]\n",
    "- 1) Naive Bayes Classifier(NB) 정확도 : 59%\n",
    "- 2) 컴플리먼트 나이브 베이즈 분류기(Complement Naive Bayes Classifier(CNB) ) 정확도 : 76%\n",
    "- 3) 로지스틱 회귀(Logistic Regression) 정확도: 81%\n",
    "- 4) 선형 서포트 벡터 머신(Linear Support Vector Machine) 정확도 : 78%\n",
    "- 5) 결정 트리(Decision Tree) 정확도: 62%\n",
    "- 6) 랜덤 포레스트(Random Forest) 정확도: 65%\n",
    "- 7) 그래디언트 부스팅 트리(GradientBoostingClassifier) 정확도 : 77%\n",
    "- 8) 앙상블 소프트 보팅(로지스틱 회귀, CNB, 그래디언트 부스팅 트리) 정확도 : 81%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exceptional-stuart",
   "metadata": {},
   "source": [
    "## 2. 빈도수 상위 5,000개의 단어만 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "documented-minister",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/datasets/reuters.py:148: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/datasets/reuters.py:149: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=5000, test_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-bangkok",
   "metadata": {},
   "source": [
    "#### 1) 데이터 복원하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "loved-malta",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제공된 로이터 뉴스 데이터를 단어key key값으로, 고유한 정수를 value로 가지는 dictionary를 word_index로 저장\n",
    "\n",
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bearing-cuisine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "# <로이터 뉴스 데이터 정의> word_index에 입력으로 했을 때, 얻는 숫자보다는 +3을 한 숫자가 원래 고유한 숫자\n",
    "    \n",
    "index_to_word = { index+3 : word for word, index in word_index.items() }\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "pressing-average",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "#<로이터 뉴스 데이터 정의>  <pad>, <sos>, <unk> 자연어 처리를 위한 맵핑 번호\n",
    "\n",
    "# index_to_word에 숫자 0은 <pad>, 숫자 1은 <sos>, 숫자 2는 <unk>를 넣어줍니다.\n",
    "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "  index_to_word[index]=token\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "headed-nigeria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> <unk> <unk> said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n"
     ]
    }
   ],
   "source": [
    "# index_to_word 를 통해 텍스트로 원래 복원하기\n",
    "\n",
    "print(' '.join([index_to_word[index] for index in x_train[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "exterior-preservation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8982\n"
     ]
    }
   ],
   "source": [
    "# 이제 전체 훈련용 뉴스 데이터와 전체 테스트용 뉴스 데이터를 텍스트 데이터로 변환\n",
    "\n",
    "decoded = []\n",
    "for i in range(len(x_train)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_train = decoded\n",
    "print(len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "european-eugene",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246\n"
     ]
    }
   ],
   "source": [
    "decoded = []\n",
    "for i in range(len(x_test)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_test = decoded\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "informative-asian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos> <unk> <unk> said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "serious-pipeline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos> the great atlantic and pacific tea co said its three year 345 mln dlr capital program will be be substantially increased to <unk> growth and expansion plans for <unk> inc and <unk> inc over the next two years a and p said the acquisition of <unk> in august 1986 and <unk> in december helped us achieve better than expected results in the fourth quarter ended february 28 its net income from continuing operations jumped 52 6 pct to 20 7 mln dlrs or 55 cts a share in the latest quarter as sales increased 48 3 pct to 1 58 billion dlrs a and p gave no details on the expanded capital program but it did say it completed the first year of the program during 1986 a and p is 52 4 pct owned by lt <unk> <unk> of west germany reuter 3']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beneficial-summary",
   "metadata": {},
   "source": [
    "#### 2) 벡터화 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "polish-antique",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dental-impression",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 4867)\n"
     ]
    }
   ],
   "source": [
    "# DTM 생성 및 DTM 크기 확인\n",
    "\n",
    "dtmvector = CountVectorizer()\n",
    "x_train_dtm = dtmvector.fit_transform(x_train)\n",
    "print(x_train_dtm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "nervous-layer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 4867)\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF Matrix는 사이킷런의 TfidfTransformer()를 통해서 생성\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidfv = tfidf_transformer.fit_transform(x_train_dtm)\n",
    "print(tfidfv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "systematic-design",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도 측정을 위해 테스트 데이터 전처리 필요, 이에 테스트 데이터 TF-IDF  행렬로 변환 필요\n",
    "\n",
    "x_test_dtm = dtmvector.transform(x_test) #테스트 데이터를 DTM으로 변환\n",
    "tfidfv_test = tfidf_transformer.transform(x_test_dtm) #DTM을 TF-IDF 행렬로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loaded-dominant",
   "metadata": {},
   "source": [
    "## 다양한 머신러닝 모델 사용해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statutory-factor",
   "metadata": {},
   "source": [
    "### 1) Naive Bayes Classifier(NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "governmental-midnight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()  # 나이브 베이즈 분류기\n",
    "model.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "every-branch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.6731967943009796\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(tfidfv_test) #테스트 데이터에 대한 예측값을 얻어 정확도 측정\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing-combine",
   "metadata": {},
   "source": [
    "### 2) 컴플리먼트 나이브 베이즈 분류기(Complement Naive Bayes Classifier(CNB) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "sexual-racing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ComplementNB()"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb = ComplementNB()\n",
    "cb.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "solved-kelly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7707034728406055\n"
     ]
    }
   ],
   "source": [
    "predicted = cb.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diagnostic-doctor",
   "metadata": {},
   "source": [
    "### 3) 로지스틱 회귀(Logistic Regression) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "statewide-february",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10000)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 소프트맥스 회귀는 LogisticRegression()을 통해서 구현\n",
    "lr = LogisticRegression(C=10000, penalty='l2')\n",
    "lr.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "choice-angola",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.8058771148708815\n"
     ]
    }
   ],
   "source": [
    "predicted = lr.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mental-reynolds",
   "metadata": {},
   "source": [
    "### 4) 선형 서포트 벡터 머신(Linear Support Vector Machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "governing-coordinate",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1000, dual=False, max_iter=500, penalty='l1')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc = LinearSVC(C=1000, penalty='l1', max_iter=500, dual=False)\n",
    "lsvc.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "allied-coating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7586821015138023\n"
     ]
    }
   ],
   "source": [
    "# 서포트 벡터 머신 사용하여 분류하기\n",
    "\n",
    "predicted = lsvc.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effective-alloy",
   "metadata": {},
   "source": [
    "### 5) 의사 결정 트리(Decision Tree) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "nutritional-harris",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=10, random_state=0)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=10, random_state=0)\n",
    "tree.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "professional-equipment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.6179875333926982\n"
     ]
    }
   ],
   "source": [
    "predicted = tree.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infinite-sight",
   "metadata": {},
   "source": [
    "### 6) 랜덤 포레스트(Random Forest) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "judicial-stand",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=5, random_state=0)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=5, random_state=0)\n",
    "forest.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "favorite-laser",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.701246660730187\n"
     ]
    }
   ],
   "source": [
    "predicted = forest.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sacred-network",
   "metadata": {},
   "source": [
    "### 7) 그래디언트 부스팅 트리(GradientBoostingClassifier) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "crazy-membrane",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(random_state=0)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grbt = GradientBoostingClassifier(random_state=0) # verbose=3\n",
    "grbt.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "unlike-martial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.767586821015138\n"
     ]
    }
   ],
   "source": [
    "predicted = grbt.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extraordinary-helping",
   "metadata": {},
   "source": [
    "### 8) 앙상블 소프트 보팅(로지스틱 회귀, CNB, 그래디언트 부스팅 트리)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "driven-indonesian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(C=10000)),\n",
       "                             ('cb', ComplementNB()),\n",
       "                             ('grbt',\n",
       "                              GradientBoostingClassifier(random_state=0))],\n",
       "                 n_jobs=-1, voting='soft')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 로지스틱 회귀, CNB, 그래디언트 부스팅 트리 모델을 사용하여 소프트 보팅을 하였을 때의 성능을 비교\n",
    "voting_classifier = VotingClassifier(estimators=[\n",
    "         ('lr', LogisticRegression(C=10000, penalty='l2')),\n",
    "        ('cb', ComplementNB()),\n",
    "        ('grbt', GradientBoostingClassifier(random_state=0))\n",
    "], voting='soft', n_jobs=-1)\n",
    "voting_classifier.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "labeled-worry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.8161175422974176\n"
     ]
    }
   ],
   "source": [
    "predicted = voting_classifier.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blank-lease",
   "metadata": {},
   "source": [
    "[num_words = 5천개 단어 머신러닝 정확도 결과]\n",
    "- 1) Naive Bayes Classifier(NB) 정확도 : 67%\n",
    "- 2) 컴플리먼트 나이브 베이즈 분류기(Complement Naive Bayes Classifier(CNB) ) 정확도 : 77%\n",
    "- 3) 로지스틱 회귀(Logistic Regression) 정확도: 80%\n",
    "- 4) 선형 서포트 벡터 머신(Linear Support Vector Machine) 정확도 : 75%\n",
    "- 5) 의사 결정 트리(Decision Tree) 정확도: 61%\n",
    "- 6) 랜덤 포레스트(Random Forest) 정확도:  70%\n",
    "- 7) 그래디언트 부스팅 트리(GradientBoostingClassifier) 정확도 : 76%\n",
    "- 8) 앙상블 소프트 보팅(로지스틱 회귀, CNB, 그래디언트 부스팅 트리) 정확도 : 81%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legislative-paradise",
   "metadata": {},
   "source": [
    "## 3. 직접 단어 개수를 설정해서 사용 \n",
    "- 나이브 베이즈 분류기, CNB, 로지스틱 회귀, 서포트 벡터 머신, 결정 트리, 랜덤 포레스트, 그래디언트 부스팅 트리, 보팅중 3개 이상"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "postal-decimal",
   "metadata": {},
   "source": [
    "### 1)  n_words = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "brazilian-assault",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/datasets/reuters.py:148: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/datasets/reuters.py:149: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=2000, test_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hourly-american",
   "metadata": {},
   "source": [
    "#### 1) 데이터 복원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "minor-paintball",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제공된 로이터 뉴스 데이터를 단어key key값으로, 고유한 정수를 value로 가지는 dictionary를 word_index로 저장\n",
    "\n",
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "divided-lexington",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "# <로이터 뉴스 데이터 정의> word_index에 입력으로 했을 때, 얻는 숫자보다는 +3을 한 숫자가 원래 고유한 숫자\n",
    "    \n",
    "index_to_word = { index+3 : word for word, index in word_index.items() }\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "worst-exclusive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "#<로이터 뉴스 데이터 정의>  <pad>, <sos>, <unk> 자연어 처리를 위한 맵핑 번호\n",
    "\n",
    "# index_to_word에 숫자 0은 <pad>, 숫자 1은 <sos>, 숫자 2는 <unk>를 넣어줍니다.\n",
    "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "  index_to_word[index]=token\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "coordinate-chile",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> <unk> <unk> said as a result of its december acquisition of <unk> co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and <unk> operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n"
     ]
    }
   ],
   "source": [
    "# index_to_word 를 통해 텍스트로 원래 복원하기\n",
    "\n",
    "print(' '.join([index_to_word[index] for index in x_train[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "actual-fields",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8982\n"
     ]
    }
   ],
   "source": [
    "# 이제 전체 훈련용 뉴스 데이터와 전체 테스트용 뉴스 데이터를 텍스트 데이터로 변환\n",
    "\n",
    "decoded = []\n",
    "for i in range(len(x_train)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_train = decoded\n",
    "print(len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "published-definition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246\n"
     ]
    }
   ],
   "source": [
    "decoded = []\n",
    "for i in range(len(x_test)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_test = decoded\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "funded-treasure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos> <unk> <unk> said as a result of its december acquisition of <unk> co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and <unk> operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "medium-jacket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos> the great <unk> and pacific <unk> co said its three year <unk> mln dlr capital program will be be substantially increased to <unk> growth and expansion plans for <unk> inc and <unk> inc over the next two years a and p said the acquisition of <unk> in august 1986 and <unk> in december helped us achieve better than expected results in the fourth quarter ended february 28 its net income from continuing operations <unk> 52 6 pct to 20 7 mln dlrs or 55 cts a share in the latest quarter as sales increased 48 3 pct to 1 58 billion dlrs a and p gave no details on the <unk> capital program but it did say it completed the first year of the program during 1986 a and p is 52 4 pct owned by lt <unk> <unk> of west germany reuter 3']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beginning-indonesia",
   "metadata": {},
   "source": [
    "#### 2) 벡터화 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "imperial-personal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "guilty-grenada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 1944)\n"
     ]
    }
   ],
   "source": [
    "# DTM 생성 및 DTM 크기 확인\n",
    "\n",
    "dtmvector = CountVectorizer()\n",
    "x_train_dtm = dtmvector.fit_transform(x_train)\n",
    "print(x_train_dtm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "sapphire-division",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 1944)\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF Matrix는 사이킷런의 TfidfTransformer()를 통해서 생성\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidfv = tfidf_transformer.fit_transform(x_train_dtm)\n",
    "print(tfidfv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "heavy-cross",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도 측정을 위해 테스트 데이터 전처리 필요, 이에 테스트 데이터 TF-IDF  행렬로 변환 필요\n",
    "\n",
    "x_test_dtm = dtmvector.transform(x_test) #테스트 데이터를 DTM으로 변환\n",
    "tfidfv_test = tfidf_transformer.transform(x_test_dtm) #DTM을 TF-IDF 행렬로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "realistic-reserve",
   "metadata": {},
   "source": [
    "### 다양한 머신러닝 모델 사용해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "skilled-photograph",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Naive Bayes Classifier(NB)\n",
    "model = MultinomialNB()  # 나이브 베이즈 분류기\n",
    "model.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "annual-university",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.6914514692787177\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(tfidfv_test) #테스트 데이터에 대한 예측값을 얻어 정확도 측정\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "related-drama",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ComplementNB()"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) 컴플리먼트 나이브 베이즈 분류기\n",
    "cb = ComplementNB()\n",
    "cb.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "beneficial-passage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7569011576135352\n"
     ]
    }
   ],
   "source": [
    "predicted = cb.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "traditional-clock",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10000)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3) 로지스틱 회귀(Logistic Regression)\n",
    "# 소프트맥스 회귀는 LogisticRegression()을 통해서 구현\n",
    "lr = LogisticRegression(C=10000, penalty='l2')\n",
    "lr.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "checked-eating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7813891362422084\n"
     ]
    }
   ],
   "source": [
    "predicted = lr.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "guided-quick",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1000, dual=False, max_iter=500, penalty='l1')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4) 선형 서포트 벡터 머신(Linear Support Vector Machine)\n",
    "lsvc = LinearSVC(C=1000, penalty='l1', max_iter=500, dual=False)\n",
    "lsvc.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "juvenile-georgia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7297417631344613\n"
     ]
    }
   ],
   "source": [
    "# 서포트 벡터 머신 사용하여 분류하기\n",
    "\n",
    "predicted = lsvc.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "freelance-updating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=10, random_state=0)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5) 의사 결정 트리(Decision Tree)\n",
    "tree = DecisionTreeClassifier(max_depth=10, random_state=0)\n",
    "tree.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "still-subdivision",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.6255565449688335\n"
     ]
    }
   ],
   "source": [
    "predicted = tree.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "binding-playback",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=5, random_state=0)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6) 랜덤 포레스트(Random Forest)\n",
    "forest = RandomForestClassifier(n_estimators=5, random_state=0)\n",
    "forest.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "atomic-smooth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.6954585930543188\n"
     ]
    }
   ],
   "source": [
    "predicted = forest.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "acquired-chart",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(random_state=0)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7) 그래디언트 부스팅 트리\n",
    "\n",
    "grbt = GradientBoostingClassifier(random_state=0) # verbose=3\n",
    "grbt.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "antique-creek",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.757346393588602\n"
     ]
    }
   ],
   "source": [
    "predicted = grbt.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "central-nigeria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(C=10000)),\n",
       "                             ('cb', ComplementNB()),\n",
       "                             ('grbt',\n",
       "                              GradientBoostingClassifier(random_state=0))],\n",
       "                 n_jobs=-1, voting='soft')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8) 앙상블 소프트 보팅(# 로지스틱 회귀, CNB, 그래디언트 부스팅 트리)\n",
    "voting_classifier = VotingClassifier(estimators=[\n",
    "         ('lr', LogisticRegression(C=10000, penalty='l2')),\n",
    "        ('cb', ComplementNB()),\n",
    "        ('grbt', GradientBoostingClassifier(random_state=0))\n",
    "], voting='soft', n_jobs=-1)\n",
    "voting_classifier.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "reflected-throw",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7978628673196795\n"
     ]
    }
   ],
   "source": [
    "predicted = voting_classifier.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exclusive-framework",
   "metadata": {},
   "source": [
    "[num_words = 2천개 단어 머신러닝 정확도 결과]\n",
    "- 1) Naive Bayes Classifier(NB) 정확도 : 69%\n",
    "- 2) 컴플리먼트 나이브 베이즈 분류기(Complement Naive Bayes Classifier(CNB) ) 정확도 : 75%\n",
    "- 3) 로지스틱 회귀(Logistic Regression) 정확도: 78%\n",
    "- 4) 선형 서포트 벡터 머신(Linear Support Vector Machine) 정확도 : 72%\n",
    "- 5) 의사 결정 트리(Decision Tree) 정확도: 62%\n",
    "- 6) 랜덤 포레스트(Random Forest) 정확도:  69%\n",
    "- 7) 그래디언트 부스팅 트리(GradientBoostingClassifier) 정확도 : 75%\n",
    "- 8) 앙상블 소프트 보팅(로지스틱 회귀, CNB, 그래디언트 부스팅 트리) 정확도 : 79%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "devoted-conclusion",
   "metadata": {},
   "source": [
    "### 2)  n_words = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "damaged-pointer",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/datasets/reuters.py:148: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/datasets/reuters.py:149: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=4000, test_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "departmental-china",
   "metadata": {},
   "source": [
    "#### 1) 데이터 복원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "after-transmission",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제공된 로이터 뉴스 데이터를 단어key key값으로, 고유한 정수를 value로 가지는 dictionary를 word_index로 저장\n",
    "\n",
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "unlikely-adapter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "# <로이터 뉴스 데이터 정의> word_index에 입력으로 했을 때, 얻는 숫자보다는 +3을 한 숫자가 원래 고유한 숫자\n",
    "    \n",
    "index_to_word = { index+3 : word for word, index in word_index.items() }\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "qualified-harvard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "#<로이터 뉴스 데이터 정의>  <pad>, <sos>, <unk> 자연어 처리를 위한 맵핑 번호\n",
    "\n",
    "# index_to_word에 숫자 0은 <pad>, 숫자 1은 <sos>, 숫자 2는 <unk>를 넣어줍니다.\n",
    "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "  index_to_word[index]=token\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "electric-forward",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> <unk> <unk> said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and <unk> operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n"
     ]
    }
   ],
   "source": [
    "# index_to_word 를 통해 텍스트로 원래 복원하기\n",
    "\n",
    "print(' '.join([index_to_word[index] for index in x_train[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "needed-tourist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8982\n"
     ]
    }
   ],
   "source": [
    "# 이제 전체 훈련용 뉴스 데이터와 전체 테스트용 뉴스 데이터를 텍스트 데이터로 변환\n",
    "\n",
    "decoded = []\n",
    "for i in range(len(x_train)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_train = decoded\n",
    "print(len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "level-kinase",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246\n"
     ]
    }
   ],
   "source": [
    "decoded = []\n",
    "for i in range(len(x_test)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_test = decoded\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "afraid-masters",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos> <unk> <unk> said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and <unk> operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "adopted-weekly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos> the great atlantic and pacific <unk> co said its three year 345 mln dlr capital program will be be substantially increased to <unk> growth and expansion plans for <unk> inc and <unk> inc over the next two years a and p said the acquisition of <unk> in august 1986 and <unk> in december helped us achieve better than expected results in the fourth quarter ended february 28 its net income from continuing operations jumped 52 6 pct to 20 7 mln dlrs or 55 cts a share in the latest quarter as sales increased 48 3 pct to 1 58 billion dlrs a and p gave no details on the expanded capital program but it did say it completed the first year of the program during 1986 a and p is 52 4 pct owned by lt <unk> <unk> of west germany reuter 3']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rational-hungarian",
   "metadata": {},
   "source": [
    "#### 2) 벡터화 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "international-horizon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "incident-stuart",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 3889)\n"
     ]
    }
   ],
   "source": [
    "# DTM 생성 및 DTM 크기 확인\n",
    "\n",
    "dtmvector = CountVectorizer()\n",
    "x_train_dtm = dtmvector.fit_transform(x_train)\n",
    "print(x_train_dtm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "sitting-triumph",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 3889)\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF Matrix는 사이킷런의 TfidfTransformer()를 통해서 생성\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidfv = tfidf_transformer.fit_transform(x_train_dtm)\n",
    "print(tfidfv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "established-edition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도 측정을 위해 테스트 데이터 전처리 필요, 이에 테스트 데이터 TF-IDF  행렬로 변환 필요\n",
    "\n",
    "x_test_dtm = dtmvector.transform(x_test) #테스트 데이터를 DTM으로 변환\n",
    "tfidfv_test = tfidf_transformer.transform(x_test_dtm) #DTM을 TF-IDF 행렬로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stupid-transformation",
   "metadata": {},
   "source": [
    "### 다양한 머신러닝 모델 사용해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "rational-enough",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Naive Bayes Classifier(NB)\n",
    "model = MultinomialNB()  # 나이브 베이즈 분류기\n",
    "model.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fossil-identity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.6838824577025824\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(tfidfv_test) #테스트 데이터에 대한 예측값을 얻어 정확도 측정\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "compact-hardwood",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ComplementNB()"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) 컴플리먼트 나이브 베이즈 분류기\n",
    "cb = ComplementNB()\n",
    "cb.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "measured-religion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7689225289403384\n"
     ]
    }
   ],
   "source": [
    "predicted = cb.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "distant-finish",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10000)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3) 로지스틱 회귀(Logistic Regression)\n",
    "# 소프트맥스 회귀는 LogisticRegression()을 통해서 구현\n",
    "lr = LogisticRegression(C=10000, penalty='l2')\n",
    "lr.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "british-white",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7978628673196795\n"
     ]
    }
   ],
   "source": [
    "predicted = lr.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "inclusive-award",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1000, dual=False, max_iter=500, penalty='l1')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4) 선형 서포트 벡터 머신(Linear Support Vector Machine)\n",
    "lsvc = LinearSVC(C=1000, penalty='l1', max_iter=500, dual=False)\n",
    "lsvc.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "australian-romance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.757346393588602\n"
     ]
    }
   ],
   "source": [
    "# 서포트 벡터 머신 사용하여 분류하기\n",
    "\n",
    "predicted = lsvc.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "failing-diagnosis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=10, random_state=0)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5) 의사 결정 트리(Decision Tree)\n",
    "tree = DecisionTreeClassifier(max_depth=10, random_state=0)\n",
    "tree.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "sixth-banana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.6202137132680321\n"
     ]
    }
   ],
   "source": [
    "predicted = tree.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "designed-cache",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=5, random_state=0)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6) 랜덤 포레스트(Random Forest)\n",
    "forest = RandomForestClassifier(n_estimators=5, random_state=0)\n",
    "forest.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "fitted-terror",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.6878895814781835\n"
     ]
    }
   ],
   "source": [
    "predicted = forest.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "permanent-ceramic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(random_state=0)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7) 그래디언트 부스팅 트리\n",
    "\n",
    "grbt = GradientBoostingClassifier(random_state=0) # verbose=3\n",
    "grbt.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "macro-bahrain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7671415850400712\n"
     ]
    }
   ],
   "source": [
    "predicted = grbt.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "superb-relation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(C=10000)),\n",
       "                             ('cb', ComplementNB()),\n",
       "                             ('grbt',\n",
       "                              GradientBoostingClassifier(random_state=0))],\n",
       "                 n_jobs=-1, voting='soft')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8) 앙상블 소프트 보팅(# 로지스틱 회귀, CNB, 그래디언트 부스팅 트리)\n",
    "voting_classifier = VotingClassifier(estimators=[\n",
    "         ('lr', LogisticRegression(C=10000, penalty='l2')),\n",
    "        ('cb', ComplementNB()),\n",
    "        ('grbt', GradientBoostingClassifier(random_state=0))\n",
    "], voting='soft', n_jobs=-1)\n",
    "voting_classifier.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "weighted-romantic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.8130008904719501\n"
     ]
    }
   ],
   "source": [
    "predicted = voting_classifier.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-delta",
   "metadata": {},
   "source": [
    "[num_words = 4천개 단어 머신러닝 정확도 결과]\n",
    "- 1) Naive Bayes Classifier(NB) 정확도 : 68%\n",
    "- 2) 컴플리먼트 나이브 베이즈 분류기(Complement Naive Bayes Classifier(CNB) ) 정확도 : 76%\n",
    "- 3) 로지스틱 회귀(Logistic Regression) 정확도: 79%\n",
    "- 4) 선형 서포트 벡터 머신(Linear Support Vector Machine) 정확도 : 75%\n",
    "- 5) 의사 결정 트리(Decision Tree) 정확도: 62%\n",
    "- 6) 랜덤 포레스트(Random Forest) 정확도:  68%\n",
    "- 7) 그래디언트 부스팅 트리(GradientBoostingClassifier) 정확도 : 76%\n",
    "- 8) 앙상블 소프트 보팅(로지스틱 회귀, CNB, 그래디언트 부스팅 트리) 정확도 : 81%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "allied-thesis",
   "metadata": {},
   "source": [
    "### 3)  n_words = 7000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "sorted-falls",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=7000, test_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rocky-workplace",
   "metadata": {},
   "source": [
    "#### 1) 데이터 복원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "advanced-lexington",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제공된 로이터 뉴스 데이터를 단어key key값으로, 고유한 정수를 value로 가지는 dictionary를 word_index로 저장\n",
    "\n",
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "important-packaging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "# <로이터 뉴스 데이터 정의> word_index에 입력으로 했을 때, 얻는 숫자보다는 +3을 한 숫자가 원래 고유한 숫자\n",
    "    \n",
    "index_to_word = { index+3 : word for word, index in word_index.items() }\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "fewer-investigator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "#<로이터 뉴스 데이터 정의>  <pad>, <sos>, <unk> 자연어 처리를 위한 맵핑 번호\n",
    "\n",
    "# index_to_word에 숫자 0은 <pad>, 숫자 1은 <sos>, 숫자 2는 <unk>를 넣어줍니다.\n",
    "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "  index_to_word[index]=token\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "annual-layout",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> <unk> <unk> said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n"
     ]
    }
   ],
   "source": [
    "# index_to_word 를 통해 텍스트로 원래 복원하기\n",
    "\n",
    "print(' '.join([index_to_word[index] for index in x_train[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "destroyed-austin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8982\n"
     ]
    }
   ],
   "source": [
    "# 이제 전체 훈련용 뉴스 데이터와 전체 테스트용 뉴스 데이터를 텍스트 데이터로 변환\n",
    "\n",
    "decoded = []\n",
    "for i in range(len(x_train)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_train = decoded\n",
    "print(len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "noticed-whale",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246\n"
     ]
    }
   ],
   "source": [
    "decoded = []\n",
    "for i in range(len(x_test)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_test = decoded\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "worst-departure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos> <unk> <unk> said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "miniature-burton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos> the great atlantic and pacific tea co said its three year 345 mln dlr capital program will be be substantially increased to <unk> growth and expansion plans for <unk> inc and <unk> inc over the next two years a and p said the acquisition of <unk> in august 1986 and <unk> in december helped us achieve better than expected results in the fourth quarter ended february 28 its net income from continuing operations jumped 52 6 pct to 20 7 mln dlrs or 55 cts a share in the latest quarter as sales increased 48 3 pct to 1 58 billion dlrs a and p gave no details on the expanded capital program but it did say it completed the first year of the program during 1986 a and p is 52 4 pct owned by lt <unk> <unk> of west germany reuter 3']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "round-trinity",
   "metadata": {},
   "source": [
    "#### 2) 벡터화 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "rural-restoration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "arctic-match",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 6807)\n"
     ]
    }
   ],
   "source": [
    "# DTM 생성 및 DTM 크기 확인\n",
    "\n",
    "dtmvector = CountVectorizer()\n",
    "x_train_dtm = dtmvector.fit_transform(x_train)\n",
    "print(x_train_dtm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "impressed-butler",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 6807)\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF Matrix는 사이킷런의 TfidfTransformer()를 통해서 생성\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidfv = tfidf_transformer.fit_transform(x_train_dtm)\n",
    "print(tfidfv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "brave-edgar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도 측정을 위해 테스트 데이터 전처리 필요, 이에 테스트 데이터 TF-IDF  행렬로 변환 필요\n",
    "\n",
    "x_test_dtm = dtmvector.transform(x_test) #테스트 데이터를 DTM으로 변환\n",
    "tfidfv_test = tfidf_transformer.transform(x_test_dtm) #DTM을 TF-IDF 행렬로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worth-religious",
   "metadata": {},
   "source": [
    "### 다양한 머신러닝 모델 사용해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "fourth-sullivan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Naive Bayes Classifier(NB)\n",
    "model = MultinomialNB()  # 나이브 베이즈 분류기\n",
    "model.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "fallen-dispatch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.6647373107747105\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(tfidfv_test) #테스트 데이터에 대한 예측값을 얻어 정확도 측정\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "liked-startup",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ComplementNB()"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) 컴플리먼트 나이브 베이즈 분류기\n",
    "cb = ComplementNB()\n",
    "cb.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "infinite-benefit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7684772929652716\n"
     ]
    }
   ],
   "source": [
    "predicted = cb.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "arctic-capitol",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10000)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3) 로지스틱 회귀(Logistic Regression)\n",
    "# 소프트맥스 회귀는 LogisticRegression()을 통해서 구현\n",
    "lr = LogisticRegression(C=10000, penalty='l2')  #학습이 과대적합 되는 것을 방지하고자 일종의 penalty를 부여 https://greatjoy.tistory.com/58\n",
    "lr.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "normal-hotel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.807212822796082\n"
     ]
    }
   ],
   "source": [
    "predicted = lr.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "excessive-german",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1000, dual=False, max_iter=500, penalty='l1')"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4) 선형 서포트 벡터 머신(Linear Support Vector Machine)\n",
    "lsvc = LinearSVC(C=1000, penalty='l1', max_iter=500, dual=False)\n",
    "lsvc.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "welsh-drunk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7689225289403384\n"
     ]
    }
   ],
   "source": [
    "# 서포트 벡터 머신 사용하여 분류하기\n",
    "\n",
    "predicted = lsvc.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "considered-threat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=10, random_state=0)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5) 의사 결정 트리(Decision Tree)\n",
    "tree = DecisionTreeClassifier(max_depth=10, random_state=0)\n",
    "tree.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "martial-shopping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.6206589492430988\n"
     ]
    }
   ],
   "source": [
    "predicted = tree.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "executed-accuracy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=5, random_state=0)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6) 랜덤 포레스트(Random Forest)\n",
    "forest = RandomForestClassifier(n_estimators=5, random_state=0)\n",
    "forest.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "useful-metadata",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.6736420302760463\n"
     ]
    }
   ],
   "source": [
    "predicted = forest.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "future-advertiser",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(random_state=0)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7) 그래디언트 부스팅 트리\n",
    "\n",
    "grbt = GradientBoostingClassifier(random_state=0) # verbose=3\n",
    "grbt.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "distinct-profit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7604630454140695\n"
     ]
    }
   ],
   "source": [
    "predicted = grbt.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "motivated-discipline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(C=10000)),\n",
       "                             ('cb', ComplementNB()),\n",
       "                             ('grbt',\n",
       "                              GradientBoostingClassifier(random_state=0))],\n",
       "                 n_jobs=-1, voting='soft')"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8) 앙상블 소프트 보팅(# 로지스틱 회귀, CNB, 그래디언트 부스팅 트리)\n",
    "voting_classifier = VotingClassifier(estimators=[\n",
    "         ('lr', LogisticRegression(C=10000, penalty='l2')),\n",
    "        ('cb', ComplementNB()),\n",
    "        ('grbt', GradientBoostingClassifier(random_state=0))\n",
    "], voting='soft', n_jobs=-1)\n",
    "voting_classifier.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "olympic-section",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.815227070347284\n"
     ]
    }
   ],
   "source": [
    "predicted = voting_classifier.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crude-therapist",
   "metadata": {},
   "source": [
    "[num_words = 7천개 단어 머신러닝 정확도 결과]\n",
    "- 1) Naive Bayes Classifier(NB) 정확도 : 66%\n",
    "- 2) 컴플리먼트 나이브 베이즈 분류기(Complement Naive Bayes Classifier(CNB) ) 정확도 : 76%\n",
    "- 3) 로지스틱 회귀(Logistic Regression) 정확도: 80%\n",
    "- 4) 선형 서포트 벡터 머신(Linear Support Vector Machine) 정확도 : 76%\n",
    "- 5) 의사 결정 트리(Decision Tree) 정확도: 62%\n",
    "- 6) 랜덤 포레스트(Random Forest) 정확도:  67%\n",
    "- 7) 그래디언트 부스팅 트리(GradientBoostingClassifier) 정확도 : 76%\n",
    "- 8) 앙상블 소프트 보팅(로지스틱 회귀, CNB, 그래디언트 부스팅 트리) 정확도 : 81%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-comedy",
   "metadata": {},
   "source": [
    "## 4. 딥러닝 모델과 비교해보기\n",
    "-  감정 분석 등에 사용했던 RNN이나 1-D CNN 등의 딥러닝 모델 중 하나를 선택해서 오늘 사용했던 데이터셋을 학습해 보고 나오는 결과를 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "representative-color",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "daily-questionnaire",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_deep, y_train_deep), (x_test_deep, y_test_deep) = reuters.load_data(num_words= None, test_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "naughty-automation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  145.96419665122906\n",
      "문장길이 최대 :  2376\n",
      "문장길이 표준편차 :  145.8784764459447\n",
      "maxlen of pad_sequence: 437\n",
      "전체 문장의 10598 % 가 maxlen 설정값 이내에 포함합니다. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. 케라스 패딩을 위한 도구  pad_sequences() 로 활용하기 \n",
    "\n",
    "total_data_text = list(x_train_deep) + list(x_test_deep)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "\n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "\n",
    "#max_len의 인자로 정수를 주면, 해당 정수로 모든 문서의 길이를 동일하게 하며 값설젇이 전체 모델 성능에 영향\n",
    "\n",
    "print('maxlen of pad_sequence:', maxlen)\n",
    "print('전체 문장의 {} % 가 maxlen 설정값 이내에 포함합니다. \\n'.format(np.sum(num_tokens < max_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "major-excellence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding 방식 변경해 보기 -앞쪽('pre')  *RNN은 입력데이터가 순차적으로 처리 마지막 입력이 무의미, 'pre'가 훨씬 유리\n",
    "\n",
    "x_train_deep = keras.preprocessing.sequence.pad_sequences(x_train_deep,padding = 'pre', maxlen = maxlen)\n",
    "x_test_deep = keras.preprocessing.sequence.pad_sequences(x_test_deep, padding = 'pre', maxlen = maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parliamentary-classroom",
   "metadata": {},
   "source": [
    "####  RNN 모델 비교\n",
    "\n",
    "<mark><b>[진행 순서]</b>\n",
    "\n",
    "1. RNN 모델 설계\n",
    "2. 훈련용 데이터셋 10000건을 분리하여 검증셋(validation set)으로 사용\n",
    "3. 모델 학습\n",
    "4. 모델 테스트셋으로 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "collaborative-present",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, None, 200)         10000000  \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 100)               120400    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 46)                4646      \n",
      "=================================================================\n",
      "Total params: 10,125,046\n",
      "Trainable params: 10,125,046\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 1. RNN 모델 설계\n",
    "vocab_size = 50000  # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 200  # 워드 벡터의 차원 수 (변경 가능한 하이퍼파라미터)\n",
    "\n",
    "# model 설계 \n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim))\n",
    "model.add(keras.layers.LSTM(100))\n",
    "model.add(keras.layers.Dense(46, activation = 'softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "failing-psychiatry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 훈련용 데이터셋 2000건을 분리하여 검증셋(validation set)으로 사용\n",
    "\n",
    "x_val = x_train_deep[:3000]\n",
    "y_val = y_train_deep[:3000]\n",
    "\n",
    "partial_x_train_deep = x_train_deep[3000:]\n",
    "partial_y_train_deep = y_train_deep[3000:]\n",
    "\n",
    "partial_y_train_deep = keras.utils.to_categorical(partial_y_train_deep)\n",
    "y_val =  keras.utils.to_categorical(y_val)\n",
    "y_test_deep = keras.utils.to_categorical(y_test_deep)\n",
    "\n",
    "es = keras.callbacks.EarlyStopping(monitor= 'val_loss', mode = 'min', verbose = 1, patience = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparative-simulation",
   "metadata": {},
   "source": [
    "- 위와 같이 지정하면 validation set 의 loss 를 monitoring 한다는 뜻\n",
    "- 만약 performance measure가 최소화 시켜야하는 것이면 mode를 min 으로, 최대화 시켜야하는 것이면 mode를 max로 지정한다. loss 의 경우, 최소화 시키는 방향으로 training 이 진행되므로 min 을 지정한다.\n",
    "- validation accuracy 가 1% 증가하지 않는 경우, 성능의 증가가 없다고 정의한다. \n",
    "\n",
    "출처: https://3months.tistory.com/424 [Deep Play]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "facial-circular",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 모델 학습\n",
    "model.compile(optimizer= 'adam', loss =  'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "statewide-source",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "187/187 [==============================] - 27s 147ms/step - loss: 0.6815 - accuracy: 0.8245 - val_loss: 1.5611 - val_accuracy: 0.6463\n",
      "Epoch 2/10\n",
      "187/187 [==============================] - 25s 134ms/step - loss: 0.5233 - accuracy: 0.8679 - val_loss: 1.6269 - val_accuracy: 0.6433\n",
      "Epoch 3/10\n",
      "187/187 [==============================] - 21s 112ms/step - loss: 0.3981 - accuracy: 0.9061 - val_loss: 1.6712 - val_accuracy: 0.6570\n",
      "Epoch 4/10\n",
      "187/187 [==============================] - 21s 114ms/step - loss: 0.3139 - accuracy: 0.9258 - val_loss: 1.7108 - val_accuracy: 0.6520\n",
      "Epoch 5/10\n",
      "187/187 [==============================] - 21s 113ms/step - loss: 0.2360 - accuracy: 0.9465 - val_loss: 1.7545 - val_accuracy: 0.6667\n",
      "Epoch 6/10\n",
      "187/187 [==============================] - 21s 112ms/step - loss: 0.1908 - accuracy: 0.9537 - val_loss: 1.7891 - val_accuracy: 0.6663\n",
      "Epoch 7/10\n",
      "187/187 [==============================] - 25s 134ms/step - loss: 0.1565 - accuracy: 0.9592 - val_loss: 1.8131 - val_accuracy: 0.6777\n",
      "Epoch 8/10\n",
      "187/187 [==============================] - 21s 112ms/step - loss: 0.1324 - accuracy: 0.9614 - val_loss: 1.8410 - val_accuracy: 0.6660\n",
      "Epoch 9/10\n",
      "187/187 [==============================] - 21s 115ms/step - loss: 0.1155 - accuracy: 0.9646 - val_loss: 1.9334 - val_accuracy: 0.6607\n",
      "Epoch 10/10\n",
      "187/187 [==============================] - 21s 113ms/step - loss: 0.1132 - accuracy: 0.9624 - val_loss: 1.9530 - val_accuracy: 0.6503\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "history_deep = model.fit(partial_x_train_deep, partial_y_train_deep, epochs= epochs , \n",
    "                         batch_size = 32,\n",
    "                         validation_data= (x_val,y_val),\n",
    "                        verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "current-preparation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 - 2s - loss: 2.0399 - accuracy: 0.6358\n",
      "[2.0398776531219482, 0.6357969641685486]\n"
     ]
    }
   ],
   "source": [
    "# 4. 모델 테스트셋으로 평가\n",
    "results = model.evaluate(x_test_deep,  y_test_deep, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungarian-campus",
   "metadata": {},
   "source": [
    "- epochs = 5 : LSTM 적용 모델 63%의 정확도 확인할수 있었음. 의사결정 트리 정확도 62%와 랜덤 포레스트 정확도 65%의 중간 정도의 성능으로 전체적으로 보팅보다 떨어지는것을 확인 할수 있었다.\n",
    "- epochs = 10 :  LSTM 적용 모델 63%의 정확도 확인할수 있었음. 의사결정 트리 정확도 62%와 랜덤 포레스트 정확도 65%의 중간 정도의 성능으로 전체적으로 보팅보다 떨어지는것을 확인 할수 있었다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transparent-sierra",
   "metadata": {},
   "source": [
    "## 루브릭\n",
    "- 3가지 단어 개수에 대해 8가지 머신러닝 기법을 적용하여 그중 최적의 솔루션을 도출하였다\n",
    "- Vocabulary size에 따른 각 머신러닝 모델의 성능변화 추이를 살피고, 해당 머신러닝 알고리즘의 특성에 근거해 원인을 분석하였다.\n",
    "- 동일한 데이터셋과 전처리 조건으로 딥러닝 모델의 성능과 비교하여 결과에 따른 원인을 분석하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "general-local",
   "metadata": {},
   "source": [
    "## 회고\n",
    "\n",
    "[결론]\n",
    "- 정확도는 8)보팅 > 3)로지스틱회귀 > 7)그래디언트 부스팅트리 > 2)CNB > 4)LSVM > 6) 랜덤포레스트> 1) NB> 5) 의사결정트리 의 순으로 성능이 좋은것으로 확인 되었다. 의사결정 트리가 고차원, 희소한 데이터에는 성능이 나오지 않는 특징이 있어서 그런것 같다. \n",
    "\n",
    "[확인 결과]\n",
    "- 1) Naive Bayes Classifier(NB)는 num_words = none 일때  정확도 59%로 가장 낮고, 2천개 단어일때 69%로 높았다. \n",
    "- 2) 컴플리먼트 나이브 베이즈 분류기(CNB) )  num_words 와 상관 없이 정확도 75%~ 76%를 유지하였다.\n",
    "- 3) 로지스틱 회귀(Logistic Regression)   num_words = 2천일때 정확도가 78%로 낮았고 대부분 78%~81%를 유지하였다.\n",
    "- 4) 선형 서포트 벡터 머신(Linear Support Vector Machine) 는  num_words = 2천일때일때 정확도가 72%로 낮았고, num_words = none일때  78%로 정확도가 높았다.\n",
    "- 5) 의사 결정 트리(Decision Tree)는 정확도가 61%~62%로 가장 성능이 좋지 않았다.\n",
    "- 6) 랜덤 포레스트(Random Forest)는  num_words = none 일때  정확도 65%로 낮고, 5천개 단어일때 70%로 높았다. \n",
    "- 7) 그래디언트 부스팅 트리(GradientBoostingClassifier) 는 정확도가 대부분 75%~77%를 유지하였다.\n",
    "- 8) 앙상블 소프트 보팅(로지스틱 회귀, CNB, 그래디언트 부스팅 트리) 는 정확도가  num_words = 2천일때 79%로 가장낮았고 대부분 81%의 정확도를 보였다. \n",
    "\n",
    "\n",
    "[num_words : 등장 빈도수 TEST 상세내용 ]\n",
    "\n",
    "[num_words = none 단어 머신러닝 정확도 결과]\n",
    "1) Naive Bayes Classifier(NB) 정확도 : 59%\n",
    "2) 컴플리먼트 나이브 베이즈 분류기(Complement Naive Bayes Classifier(CNB) ) 정확도 : 76%\n",
    "3) 로지스틱 회귀(Logistic Regression) 정확도: 81%\n",
    "4) 선형 서포트 벡터 머신(Linear Support Vector Machine) 정확도 : 78%\n",
    "5) 의사 결정 트리(Decision Tree) 정확도: 62%\n",
    "6) 랜덤 포레스트(Random Forest) 정확도: 65%\n",
    "7) 그래디언트 부스팅 트리(GradientBoostingClassifier) 정확도 : 77%\n",
    "8) 앙상블 소프트 보팅(로지스틱 회귀, CNB, 그래디언트 부스팅 트리) 정확도 : 81%\n",
    "\n",
    "\n",
    "[num_words = 5천개 단어 머신러닝 정확도 결과]\n",
    "- 1) Naive Bayes Classifier(NB) 정확도 : 67%\n",
    "- 2) 컴플리먼트 나이브 베이즈 분류기(Complement Naive Bayes Classifier(CNB) ) 정확도 : 77%\n",
    "- 3) 로지스틱 회귀(Logistic Regression) 정확도: 80%\n",
    "- 4) 선형 서포트 벡터 머신(Linear Support Vector Machine) 정확도 : 75%\n",
    "- 5) 의사 결정 트리(Decision Tree) 정확도: 61%\n",
    "- 6) 랜덤 포레스트(Random Forest) 정확도:  70%\n",
    "- 7) 그래디언트 부스팅 트리(GradientBoostingClassifier) 정확도 : 76%\n",
    "- 8) 앙상블 소프트 보팅(로지스틱 회귀, CNB, 그래디언트 부스팅 트리) 정확도 : 81%\n",
    "\n",
    "[num_words = 2천개 단어 머신러닝 정확도 결과]\n",
    "- 1) Naive Bayes Classifier(NB) 정확도 : 69%\n",
    "- 2) 컴플리먼트 나이브 베이즈 분류기(Complement Naive Bayes Classifier(CNB) ) 정확도 : 75%\n",
    "- 3) 로지스틱 회귀(Logistic Regression) 정확도: 78%\n",
    "- 4) 선형 서포트 벡터 머신(Linear Support Vector Machine) 정확도 : 72%\n",
    "- 5) 의사 결정 트리(Decision Tree) 정확도: 62%\n",
    "- 6) 랜덤 포레스트(Random Forest) 정확도:  69%\n",
    "- 7) 그래디언트 부스팅 트리(GradientBoostingClassifier) 정확도 : 75%\n",
    "- 8) 앙상블 소프트 보팅(로지스틱 회귀, CNB, 그래디언트 부스팅 트리) 정확도 : 79%\n",
    "\n",
    "[num_words = 4천개 단어 머신러닝 정확도 결과]\n",
    "- 1) Naive Bayes Classifier(NB) 정확도 : 68%\n",
    "- 2) 컴플리먼트 나이브 베이즈 분류기(Complement Naive Bayes Classifier(CNB) ) 정확도 : 76%\n",
    "- 3) 로지스틱 회귀(Logistic Regression) 정확도: 79%\n",
    "- 4) 선형 서포트 벡터 머신(Linear Support Vector Machine) 정확도 : 75%\n",
    "- 5) 의사 결정 트리(Decision Tree) 정확도: 62%\n",
    "- 6) 랜덤 포레스트(Random Forest) 정확도:  68%\n",
    "- 7) 그래디언트 부스팅 트리(GradientBoostingClassifier) 정확도 : 76%\n",
    "- 8) 앙상블 소프트 보팅(로지스틱 회귀, CNB, 그래디언트 부스팅 트리) 정확도 : 81%\n",
    "\n",
    "[num_words = 7천개 단어 머신러닝 정확도 결과]\n",
    "- 1) Naive Bayes Classifier(NB) 정확도 : 66%\n",
    "- 2) 컴플리먼트 나이브 베이즈 분류기(Complement Naive Bayes Classifier(CNB) ) 정확도 : 76%\n",
    "- 3) 로지스틱 회귀(Logistic Regression) 정확도: 80%\n",
    "- 4) 선형 서포트 벡터 머신(Linear Support Vector Machine) 정확도 : 76%\n",
    "- 5) 의사 결정 트리(Decision Tree) 정확도: 62%\n",
    "- 6) 랜덤 포레스트(Random Forest) 정확도:  67%\n",
    "- 7) 그래디언트 부스팅 트리(GradientBoostingClassifier) 정확도 : 76%\n",
    "- 8) 앙상블 소프트 보팅(로지스틱 회귀, CNB, 그래디언트 부스팅 트리) 정확도 : 81%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beneficial-moses",
   "metadata": {},
   "source": [
    "[궁금한점] *간만에 창호퍼실님께 물어볼게 생겼는데 퇴실에 다른 퍼실님이 오셨다. 이렇게 또 타이밍이 어긋나는 ㅋㅋ\n",
    "\n",
    "- 학습이 과적합 되는것을 방지하고자 일정의 패널티를 부여하고자 로지스틱회귀는 L2를 선형 서포트 벡터머신은  L1 규제항을 추가 하는데\n",
    "개념이 타블로그( https://greatjoy.tistory.com/58)에서 봐도 좀 어려운감이 있다. 서로 달리 써도 되는건지도 궁금? \n",
    "\n",
    "[보완할점]\n",
    "- 오래전 배워했던 RNN 딥러닝 모델이라 기억이 잘 나지 않아 반정도만 이해한것 같다.  추후 밑시딥2에서 다시 살펴봐야할것 같다. \n",
    "\n",
    "[개선요청]\n",
    "- 3번 지문의 내용 개선 필요( 직접 단어 개수 설정해서 사용하되 사용할 아래 모델중 3가지 이상 실험하라의 뜻으로도 해석되는데 루브릭이 뒷부분에 나오기 때문에 사전에 자세하게 읽지 않으면 햇갈릴것 같습니다.\n",
    "전 : 위 단계에서 5000으로 제시된 num_words를 다양하게 바꾸어 가며 성능을 확인해보세요. 변화된 단어 수에 따른 모델의 성능을 연구해 보세요. 최소 3가지 경우 이상을 실험해 보기를 권합니다.\n",
    "후 : 최소 3가지 이상의 num_words 단어 개수 변경 실험을 진행해 보고 매 진행시 마다 아래의 8가지 모델 전부를 사용하시오) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
