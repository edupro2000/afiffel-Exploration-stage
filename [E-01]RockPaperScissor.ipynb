{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "[E-01]RockPaperScissor.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mature-adrian"
      },
      "source": [
        "# 인공지능 가위바위보"
      ],
      "id": "mature-adrian"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "optional-scholar",
        "outputId": "46bfbe9c-5370-4c43-945c-fdb581927938"
      },
      "source": [
        "from PIL import Image\n",
        "import os, glob\n",
        "\n",
        "print(\"PIL 라이브러리 import 완료!\")"
      ],
      "id": "optional-scholar",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PIL 라이브러리 import 완료!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "indoor-necessity",
        "outputId": "4208dcba-c69f-488c-f8e0-ba7f9691ab56"
      },
      "source": [
        "import os\n",
        "\n",
        "def resize_images(img_path):\n",
        "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
        "    \n",
        "\tprint(len(images), \" images to be resized.\")\n",
        "\n",
        "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
        "\ttarget_size=(28,28)\n",
        "\tfor img in images:\n",
        "\t\told_img=Image.open(img)\n",
        "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
        "\t\tnew_img.save(img, \"JPEG\")\n",
        "    \n",
        "\tprint(len(images), \" images resized.\")\n",
        "\t\n",
        "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
        "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
        "resize_images(image_dir_path)\n",
        "\n",
        "print(\"가위 이미지 resize 완료!\")"
      ],
      "id": "indoor-necessity",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100  images to be resized.\n",
            "100  images resized.\n",
            "가위 이미지 resize 완료!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "medical-intro",
        "outputId": "521cdcd4-4e5e-430c-fdbf-22d5cf451693"
      },
      "source": [
        "import os\n",
        "\n",
        "def resize_images(img_path):\n",
        "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
        "    \n",
        "\tprint(len(images), \" images to be resized.\")\n",
        "\n",
        "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
        "\ttarget_size=(28,28)\n",
        "\tfor img in images:\n",
        "\t\told_img=Image.open(img)\n",
        "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
        "\t\tnew_img.save(img, \"JPEG\")\n",
        "    \n",
        "\tprint(len(images), \" images resized.\")\n",
        "\t\n",
        "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
        "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
        "resize_images(image_dir_path)\n",
        "\n",
        "print(\"바위 이미지 resize 완료!\")"
      ],
      "id": "medical-intro",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100  images to be resized.\n",
            "100  images resized.\n",
            "바위 이미지 resize 완료!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cosmetic-vatican",
        "outputId": "5245aba4-5bb0-4ee5-f218-4ba96be8c471"
      },
      "source": [
        "import os\n",
        "\n",
        "def resize_images(img_path):\n",
        "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
        "    \n",
        "\tprint(len(images), \" images to be resized.\")\n",
        "\n",
        "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
        "\ttarget_size=(28,28)\n",
        "\tfor img in images:\n",
        "\t\told_img=Image.open(img)\n",
        "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
        "\t\tnew_img.save(img, \"JPEG\")\n",
        "    \n",
        "\tprint(len(images), \" images resized.\")\n",
        "\t\n",
        "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
        "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
        "resize_images(image_dir_path)\n",
        "\n",
        "print(\"보 이미지 resize 완료!\")"
      ],
      "id": "cosmetic-vatican",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "91  images to be resized.\n",
            "91  images resized.\n",
            "보 이미지 resize 완료!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "electoral-modern",
        "outputId": "dcc441ab-fbad-47dd-953f-e833664a3125"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def load_data(img_path, number_of_data=291):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
        "    # 가위 : 0, 바위 : 1, 보 : 2\n",
        "    img_size=28\n",
        "    color=3\n",
        "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
        "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
        "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
        "\n",
        "    idx=0\n",
        "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
        "        img = np.array(Image.open(file),dtype=np.int32)\n",
        "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
        "        labels[idx]=0   # 가위 : 0\n",
        "        idx=idx+1\n",
        "\n",
        "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
        "        img = np.array(Image.open(file),dtype=np.int32)\n",
        "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
        "        labels[idx]=1   # 바위 : 1\n",
        "        idx=idx+1  \n",
        "    \n",
        "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
        "        img = np.array(Image.open(file),dtype=np.int32)\n",
        "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
        "        labels[idx]=2   # 보 : 2\n",
        "        idx=idx+1\n",
        "        \n",
        "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
        "    return imgs, labels\n",
        "\n",
        "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
        "(x_train, y_train)=load_data(image_dir_path)\n",
        "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
        "\n",
        "print(\"x_train shape: {}\".format(x_train.shape))\n",
        "print(\"y_train shape: {}\".format(y_train.shape))"
      ],
      "id": "electoral-modern",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "학습데이터(x_train)의 이미지 개수는 291 입니다.\n",
            "x_train shape: (291, 28, 28, 3)\n",
            "y_train shape: (291,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rising-conditions",
        "outputId": "742df028-d9c7-440c-8c28-401ba58466fe"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(x_train[0])\n",
        "print('라벨: ', y_train[0])"
      ],
      "id": "rising-conditions",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "라벨:  0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "strategic-vertical",
        "outputId": "0e33a6a9-e6ca-400c-9c07-a82c0dfa50b0"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "# model을 직접 만들어 보세요.\n",
        "# Hint! model의 입력/출력부에 특히 유의해 주세요. 가위바위보 데이터셋은 MNIST 데이터셋과 어떤 점이 달라졌나요?\n",
        "\n",
        "model=keras.models.Sequential()\n",
        "\n",
        "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
        "model.add(keras.layers.MaxPool2D(2,2))\n",
        "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
        "model.add(keras.layers.MaxPooling2D((2,2)))\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(32, activation='relu'))  #32개 노드\n",
        "model.add(keras.layers.Dense(10, activation='softmax')) #+@ 값이 나오는경우 b 편향의 값이다. \n",
        "\n",
        "model.summary()"
      ],
      "id": "strategic-vertical",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_2 (Conv2D)            (None, 26, 26, 16)        448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 11, 11, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 800)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                25632     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 31,050\n",
            "Trainable params: 31,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "informative-forth",
        "outputId": "7ed3bd9b-c661-45d8-cd4b-25b9ad3a678d"
      },
      "source": [
        "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
        "print(\"Before Reshape - x_train_norm shape: {}\".format(x_train_norm.shape)) \n",
        "x_train_reshaped=x_train_norm.reshape( -1, 28, 28, 3) # 데이터갯수에 -1을 쓰면 reshape시 자동계산됩니다. \n",
        "print(\"After Reshape - x_train_reshaped shape: {}\".format(x_train_reshaped.shape)) \n",
        "\n",
        "# Hint! model.compile()과 model.fit()을 사용해 봅시다.\n",
        "model.compile(optimizer='adam', \n",
        "loss='sparse_categorical_crossentropy', \n",
        "metrics=['accuracy'])\n",
        "model.fit(x_train_reshaped, y_train, epochs=30)"
      ],
      "id": "informative-forth",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before Reshape - x_train_norm shape: (291, 28, 28, 3)\n",
            "After Reshape - x_train_reshaped shape: (291, 28, 28, 3)\n",
            "Epoch 1/30\n",
            "10/10 [==============================] - 4s 159ms/step - loss: 2.0094 - accuracy: 0.2834\n",
            "Epoch 2/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2431 - accuracy: 0.3537\n",
            "Epoch 3/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1318 - accuracy: 0.3632\n",
            "Epoch 4/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0172 - accuracy: 0.5095\n",
            "Epoch 5/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0480 - accuracy: 0.3795\n",
            "Epoch 6/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0215 - accuracy: 0.4280\n",
            "Epoch 7/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9489 - accuracy: 0.6139\n",
            "Epoch 8/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9952 - accuracy: 0.5304\n",
            "Epoch 9/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9108 - accuracy: 0.5881\n",
            "Epoch 10/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8417 - accuracy: 0.6537\n",
            "Epoch 11/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8073 - accuracy: 0.6808\n",
            "Epoch 12/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7700 - accuracy: 0.6600\n",
            "Epoch 13/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7616 - accuracy: 0.6312\n",
            "Epoch 14/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7810 - accuracy: 0.6052\n",
            "Epoch 15/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6119 - accuracy: 0.7786\n",
            "Epoch 16/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5505 - accuracy: 0.8485\n",
            "Epoch 17/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5353 - accuracy: 0.7619\n",
            "Epoch 18/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5400 - accuracy: 0.8212\n",
            "Epoch 19/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4741 - accuracy: 0.8625\n",
            "Epoch 20/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4401 - accuracy: 0.8627\n",
            "Epoch 21/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4734 - accuracy: 0.7922\n",
            "Epoch 22/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6169 - accuracy: 0.6758\n",
            "Epoch 23/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8989 - accuracy: 0.6297\n",
            "Epoch 24/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5418 - accuracy: 0.7924\n",
            "Epoch 25/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5017 - accuracy: 0.8359\n",
            "Epoch 26/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.3979 - accuracy: 0.8997\n",
            "Epoch 27/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.3880 - accuracy: 0.8604\n",
            "Epoch 28/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.3918 - accuracy: 0.8532\n",
            "Epoch 29/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.3440 - accuracy: 0.8829\n",
            "Epoch 30/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.3140 - accuracy: 0.9128\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f90fe2a23d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "behind-perry",
        "outputId": "1f7a00ad-ad91-43f0-ea30-88881fe3b13d"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def load_data(img_path, number_of_data=300):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
        "    # 가위 : 0, 바위 : 1, 보 : 2\n",
        "    img_size=28\n",
        "    color=3\n",
        "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
        "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
        "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
        "\n",
        "    idx=0\n",
        "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
        "        img = np.array(Image.open(file),dtype=np.int32)\n",
        "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
        "        labels[idx]=0   # 가위 : 0\n",
        "        idx=idx+1\n",
        "\n",
        "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
        "        img = np.array(Image.open(file),dtype=np.int32)\n",
        "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
        "        labels[idx]=1   # 바위 : 1\n",
        "        idx=idx+1  \n",
        "    \n",
        "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
        "        img = np.array(Image.open(file),dtype=np.int32)\n",
        "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
        "        labels[idx]=2   # 보 : 2\n",
        "        idx=idx+1\n",
        "        \n",
        "    print(\"학습테스터(x_test)의 이미지 개수는\", idx,\"입니다.\")\n",
        "    return imgs, labels\n",
        "\n",
        "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
        "(x_test, y_test)=load_data(image_dir_path)\n",
        "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
        "\n",
        "print(\"x_test shape: {}\".format(x_test.shape))\n",
        "print(\"y_test shape: {}\".format(y_test.shape))"
      ],
      "id": "behind-perry",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "학습테스터(x_test)의 이미지 개수는 300 입니다.\n",
            "x_test shape: (300, 28, 28, 3)\n",
            "y_test shape: (300,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "variable-saturday",
        "outputId": "9ff28367-3e85-4fa0-a0b2-1ef824302664"
      },
      "source": [
        "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
        "model=keras.models.Sequential()\n",
        "\n",
        "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
        "model.add(keras.layers.MaxPool2D(2,2))\n",
        "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
        "model.add(keras.layers.MaxPooling2D((2,2)))\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(30, activation='relu'))  #32개 노드\n",
        "model.add(keras.layers.Dense(10, activation='softmax')) #+@ 값이 나오는경우 b 편향의 값이다. \n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Hint! model.evaluate()을 사용해 봅시다.\n",
        "print(\"Before Reshape - x_train_norm shape: {}\".format(x_train_norm.shape)) \n",
        "print(\"Before Reshape - x_test_norm shape: {}\".format(x_test_norm.shape)) \n",
        "x_train_reshaped=x_train_norm.reshape( -1, 28, 28, 3) # 데이터갯수에 -1을 쓰면 reshape시 자동계산됩니다. \n",
        "\n",
        "x_test_reshaped=x_test_norm.reshape( -1, 28, 28, 3)  # 데이터갯수에 -1을 쓰면 reshape시 자동계산됩니다. \n",
        "\n",
        "print(\"After Reshape - x_train_reshaped shape: {}\".format(x_train_reshaped.shape)) \n",
        "print(\"After Reshape - x_test_reshaped shape: {}\".format(x_test_reshaped.shape))\n",
        "\n",
        "model.compile(optimizer='adam', \n",
        "loss='sparse_categorical_crossentropy', \n",
        "metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.fit(x_train_reshaped, y_train, epochs=30)"
      ],
      "id": "variable-saturday",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 26, 26, 16)        448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 13, 13, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 11, 11, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 5, 5, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 800)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 32)                25632     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 31,050\n",
            "Trainable params: 31,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Before Reshape - x_train_norm shape: (291, 28, 28, 3)\n",
            "Before Reshape - x_test_norm shape: (300, 28, 28, 3)\n",
            "After Reshape - x_train_reshaped shape: (291, 28, 28, 3)\n",
            "After Reshape - x_test_reshaped shape: (300, 28, 28, 3)\n",
            "Epoch 1/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.1767 - accuracy: 0.2345\n",
            "Epoch 2/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.5064 - accuracy: 0.3245\n",
            "Epoch 3/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1969 - accuracy: 0.3342\n",
            "Epoch 4/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1050 - accuracy: 0.3989\n",
            "Epoch 5/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1201 - accuracy: 0.3668\n",
            "Epoch 6/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0748 - accuracy: 0.4226\n",
            "Epoch 7/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0298 - accuracy: 0.4940\n",
            "Epoch 8/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0004 - accuracy: 0.4629\n",
            "Epoch 9/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0386 - accuracy: 0.5243\n",
            "Epoch 10/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9503 - accuracy: 0.5817\n",
            "Epoch 11/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8671 - accuracy: 0.6418\n",
            "Epoch 12/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8027 - accuracy: 0.7724\n",
            "Epoch 13/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7778 - accuracy: 0.6394\n",
            "Epoch 14/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7725 - accuracy: 0.6251\n",
            "Epoch 15/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7123 - accuracy: 0.7306\n",
            "Epoch 16/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6976 - accuracy: 0.7644\n",
            "Epoch 17/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7145 - accuracy: 0.6628\n",
            "Epoch 18/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6169 - accuracy: 0.7498\n",
            "Epoch 19/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5424 - accuracy: 0.7877\n",
            "Epoch 20/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5553 - accuracy: 0.8267\n",
            "Epoch 21/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.8477\n",
            "Epoch 22/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4706 - accuracy: 0.8000\n",
            "Epoch 23/30\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.8714\n",
            "Epoch 24/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4211 - accuracy: 0.8895\n",
            "Epoch 25/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.8231\n",
            "Epoch 26/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.8301\n",
            "Epoch 27/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.3857 - accuracy: 0.8884\n",
            "Epoch 28/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.3929 - accuracy: 0.8719\n",
            "Epoch 29/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.3472 - accuracy: 0.8829\n",
            "Epoch 30/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.3473 - accuracy: 0.8975\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f919bfc8750>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "animal-spain",
        "outputId": "1f6a7d1c-9036-4400-dffc-ab5dd05cb4b1"
      },
      "source": [
        "#더 좋은 네트워크\n",
        "model=keras.models.Sequential()\n",
        "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
        "model.add(keras.layers.MaxPool2D(2,2))\n",
        "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
        "model.add(keras.layers.MaxPooling2D((2,2)))\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(38, activation='relu')) #38개 노드\n",
        "model.add(keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "model.compile(optimizer='adam',\n",
        "             loss='sparse_categorical_crossentropy',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "# 모델 훈련\n",
        "model.fit(x_train_reshaped, y_train, epochs=n_train_epoch)\n",
        "\n",
        "# 모델 시험\n",
        "test_loss, test_accuracy = model.evaluate(x_test_reshaped, y_test, verbose=2)\n",
        "print(\"test_loss: {} \".format(test_loss))\n",
        "print(\"test_accuracy: {}\".format(test_accuracy))"
      ],
      "id": "animal-spain",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_16 (Conv2D)           (None, 26, 26, 16)        448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 13, 13, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 11, 11, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling (None, 5, 5, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 800)               0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 38)                30438     \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 10)                390       \n",
            "=================================================================\n",
            "Total params: 35,916\n",
            "Trainable params: 35,916\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.9988 - accuracy: 0.2859\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2030 - accuracy: 0.3387\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1447 - accuracy: 0.3319\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0870 - accuracy: 0.3355\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0595 - accuracy: 0.3774\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0704 - accuracy: 0.5738\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9485 - accuracy: 0.6604\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8967 - accuracy: 0.7143\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8782 - accuracy: 0.6776\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8064 - accuracy: 0.7147\n",
            "10/10 - 0s - loss: 0.9220 - accuracy: 0.6633\n",
            "test_loss: 0.922035813331604 \n",
            "test_accuracy: 0.6633333563804626\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8mJbFjN9gP2"
      },
      "source": [
        "**회고**\n",
        "오버피팅을 극복하기 위한 적절한 시도가 있었는가? 점수 미획득"
      ],
      "id": "W8mJbFjN9gP2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oS5BRBR0AJR2"
      },
      "source": [
        "predicted_result = model.predict(x_test)  # model이 추론한 확률값. \n",
        "predicted_labels = np.argmax(predicted_result, axis=1)\n",
        "\n",
        "idx=0  #1번째 x_test를 살펴보자. \n",
        "print('model.predict() 결과 : ', predicted_result[idx])\n",
        "print('model이 추론한 가장 가능성이 높은 결과 : ', predicted_labels[idx])\n",
        "print('실제 데이터의 라벨 : ', y_test[idx])"
      ],
      "id": "oS5BRBR0AJR2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0282GKe9qo9"
      },
      "source": [
        "plt.imshow(x_test[idx],cmap=plt.cm.binary)\n",
        "plt.show()"
      ],
      "id": "S0282GKe9qo9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9LMSzSt9qxJ"
      },
      "source": [
        "\n",
        "import random\n",
        "wrong_predict_list=[]\n",
        "for i, _ in enumerate(predicted_labels):\n",
        "    # i번째 test_labels과 y_test이 다른 경우만 모아 봅시다. \n",
        "    if predicted_labels[i] != y_test[i]:\n",
        "        wrong_predict_list.append(i)\n",
        "\n",
        "# wrong_predict_list 에서 랜덤하게 10개만 뽑아봅시다.\n",
        "samples = random.choices(population=wrong_predict_list, k=10)\n",
        "\n",
        "for n in samples:\n",
        "    print(\"예측확률분포: \" + str(predicted_result[n]))\n",
        "    print(\"라벨: \" + str(y_test[n]) + \", 예측결과: \" + str(predicted_labels[n]))\n",
        "    plt.imshow(x_test[n], cmap=plt.cm.binary)\n",
        "    plt.show()"
      ],
      "id": "D9LMSzSt9qxJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orPkhfCF9q6R"
      },
      "source": [
        ""
      ],
      "id": "orPkhfCF9q6R",
      "execution_count": null,
      "outputs": []
    }
  ]
}